{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Topic:** Kaggle Challenge [Quora Question Pairs](https://www.kaggle.com/c/quora-question-pairs/data)\n",
    "\n",
    "Which of the provided pairs of questions contain two questions with the same meaning? The ground truth is the set of labels that have been supplied by human experts. The ground truth labels are inherently subjective, as the true meaning of sentences can never be known with certainty. Human labeling is also a 'noisy' process, and reasonable people will disagree. As a result, the ground truth labels on this dataset should be taken to be 'informed' but not 100% accurate, and may include incorrect labeling. The labels, on the whole, represent a reasonable consensus, but this may often not be true on a case by case basis for individual items in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scores:**\n",
    "\n",
    " - log_loss: official competition score\n",
    " - accuracy: relevant in real life"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General workflow:**\n",
    "\n",
    "- load train data set\n",
    "- cleanup (NaN's, non-English)\n",
    "- tokenize\n",
    "- perform semantic indexing/analysis\n",
    "- compute similarity scores per pair\n",
    "- train a classification algorithm for score -> is duplicate prediction\n",
    "- compute scores for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import gzip\n",
    "import re\n",
    "\n",
    "# logging for gensim (set to INFO)\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %matplotlib inline\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    sns.set()\n",
    "except (NameError) as e:\n",
    "    print(\"{}: No matplotlib graphics\".format(e))\n",
    "    plt = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.utils import resample\n",
    "import sklearn.metrics.pairwise as smp\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "\n",
    "from sklearn.metrics import log_loss, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-08 18:49:53,716 : INFO : 'pattern' package not found; tag filters are not available for English\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.4.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gensim\n",
    "from gensim import corpora, models, similarities, matutils, \\\n",
    "    __version__ as gensim_version\n",
    "gensim_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(381310, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the cleaned train set:\n",
    "clean_file = './data/quora/clean.csv.gz'\n",
    "df = pd.read_csv(clean_file, header=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "ratio_1 = df['is_duplicate'].mean()\n",
    "subset_size = -1 # 10000\n",
    "\n",
    "if subset_size > 0:\n",
    "    # Use a smaller sub-set to speed up the process; preserve the ratio\n",
    "    # of is_duplicate:\n",
    "    n_samples = min(subset_size, df.shape[0]-1)\n",
    "\n",
    "    n_samples_1 = int(ratio_1 * n_samples)\n",
    "    use_df = pd.concat([\n",
    "            shuffle(df[df['is_duplicate'] == 0], n_samples=(n_samples - n_samples_1)),\n",
    "            shuffle(df[df['is_duplicate'] == 1], n_samples=n_samples_1)\n",
    "        ],\n",
    "        ignore_index=True\n",
    "    )\n",
    "else:\n",
    "    use_df = df\n",
    "    \n",
    "use_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the questions and the target flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = use_df['question1'].values\n",
    "q2 = use_df['question2'].values\n",
    "is_dup = use_df['is_duplicate'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimal EDA, look for duplicate questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_unique, q1_unique_counts = \\\n",
    "    np.unique(q1, return_index=False, return_inverse=False, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_num_dups, q1_dups_dist = \\\n",
    "    np.unique(q1_unique_counts, return_index=False, return_inverse=False, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa634704668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if plt:\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 4))\n",
    "    xticks = np.arange(q1_num_dups.min(), q1_num_dups.max()+1)\n",
    "\n",
    "    ax[0].bar(q1_num_dups, q1_dups_dist)\n",
    "    #ax[0].set_xticks(xticks)\n",
    "    ax[0].set_title(\"Duplicate Q1 Distribution\")\n",
    "    ax[0].set_xlabel(\"# Duplicates\")\n",
    "    ax[0].set_ylabel(\"Count\")\n",
    "\n",
    "    ax[1].bar(q1_num_dups, q1_dups_dist, log=True)\n",
    "    #ax[1].set_xticks(xticks)\n",
    "    ax[1].set_title(\"Duplicate Q1 Distribution (Log Scale)\")\n",
    "    ax[1].set_xlabel(\"# Duplicates\")\n",
    "    ax[1].set_ylabel(\"Count\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split 80/20 train/test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_train, q1_test, \\\n",
    "    q2_train, q2_test, \\\n",
    "    is_dup_train, is_dup_test = \\\n",
    "        train_test_split(q1, q2, is_dup, test_size=.2, stratify=is_dup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize the text; use both q1 and q2 (why? TBD):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "stemmer = nltk.stem.porter.PorterStemmer().stem\n",
    "\n",
    "def tokenizer(doc, min_len=2):\n",
    "    # Normalize case:\n",
    "    doc = doc.lower()\n",
    "    # Separate on non-alpha:\n",
    "    tokens = re.split(r'[^a-z0-9]+', doc)\n",
    "    # Return all the tokens len >= min_len, stemmed:\n",
    "    words = filter(lambda t: len(t) >= min_len, tokens)\n",
    "    if stemmer:\n",
    "        words = map(stemmer, words)\n",
    "    return list(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(\n",
    "    ngram_range=(1, 2), \n",
    "    stop_words=\"english\", \n",
    "    token_pattern=r'(?i)\\b[a-z]{2,}\\b', #words with >= 2 alpha chars,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "cvec.fit(np.concatenate((q1_train, q2_train)))\n",
    "id2word = dict((v, k) for k, v in cvec.vocabulary_.items())\n",
    "\n",
    "q1_train_tfidf = cvec.transform(q1_train)\n",
    "q1_train_corpus = matutils.Sparse2Corpus(q1_train_tfidf.transpose())\n",
    "\n",
    "q2_train_tfidf = cvec.transform(q2_train)\n",
    "q2_train_corpus = matutils.Sparse2Corpus(q2_train_tfidf.transpose())\n",
    "\n",
    "q1_test_tfidf = cvec.transform(q1_test)\n",
    "q1_test_corpus = matutils.Sparse2Corpus(q1_test_tfidf.transpose())\n",
    "\n",
    "q2_test_tfidf = cvec.transform(q2_test)\n",
    "q2_test_corpus = matutils.Sparse2Corpus(q2_test_tfidf.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectorizer = repr(cvec) + ' + custom tokenizer + stemmer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build LDA model on based on q1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-08 18:50:01,637 : INFO : using symmetric alpha at 0.005\n",
      "2018-03-08 18:50:01,638 : INFO : using symmetric eta at 0.005\n",
      "2018-03-08 18:50:01,644 : INFO : using serial LDA version on this node\n",
      "2018-03-08 18:50:03,309 : INFO : running online LDA training, 200 topics, 10 passes over the supplied corpus of 8000 documents, updating every 14000 documents, evaluating every ~8000 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2018-03-08 18:50:03,311 : INFO : training LDA model using 7 processes\n",
      "2018-03-08 18:50:03,350 : INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #2000/8000, outstanding queue size 1\n",
      "2018-03-08 18:50:03,703 : INFO : PROGRESS: pass 0, dispatched chunk #1 = documents up to #4000/8000, outstanding queue size 2\n",
      "2018-03-08 18:50:04,374 : INFO : PROGRESS: pass 0, dispatched chunk #2 = documents up to #6000/8000, outstanding queue size 3\n",
      "2018-03-08 18:50:04,381 : INFO : PROGRESS: pass 0, dispatched chunk #3 = documents up to #8000/8000, outstanding queue size 4\n",
      "2018-03-08 18:50:08,859 : INFO : topic #34 (0.005): 0.009*\"whi\" + 0.006*\"differ\" + 0.005*\"doe\" + 0.004*\"buy\" + 0.004*\"act\" + 0.004*\"best\" + 0.004*\"scan\" + 0.004*\"ct scan\" + 0.004*\"ct\" + 0.004*\"strategi\"\n",
      "2018-03-08 18:50:08,861 : INFO : topic #84 (0.005): 0.014*\"whi\" + 0.007*\"doe\" + 0.006*\"best\" + 0.005*\"love\" + 0.004*\"ipod\" + 0.003*\"engin\" + 0.003*\"abroad\" + 0.003*\"school\" + 0.003*\"peopl\" + 0.003*\"touch\"\n",
      "2018-03-08 18:50:08,861 : INFO : topic #175 (0.005): 0.007*\"whi\" + 0.004*\"file\" + 0.004*\"major\" + 0.003*\"question\" + 0.003*\"way\" + 0.003*\"use\" + 0.003*\"trade union\" + 0.003*\"tip\" + 0.003*\"wa\" + 0.003*\"trade\"\n",
      "2018-03-08 18:50:08,862 : INFO : topic #92 (0.005): 0.009*\"whi\" + 0.009*\"doe\" + 0.006*\"money\" + 0.004*\"polic\" + 0.004*\"hotel\" + 0.004*\"500\" + 0.003*\"1000\" + 0.003*\"500 1000\" + 0.003*\"best\" + 0.003*\"improv\"\n",
      "2018-03-08 18:50:08,863 : INFO : topic #199 (0.005): 0.007*\"learn\" + 0.007*\"differ\" + 0.005*\"whi\" + 0.004*\"movi\" + 0.004*\"india\" + 0.004*\"best\" + 0.003*\"comput\" + 0.003*\"gener\" + 0.003*\"world\" + 0.003*\"friend\"\n",
      "2018-03-08 18:50:08,880 : INFO : topic diff=194.171326, rho=1.000000\n",
      "2018-03-08 18:50:11,121 : INFO : -12.277 per-word bound, 4961.9 perplexity estimate based on a held-out corpus of 2000 documents with 19612 words\n",
      "2018-03-08 18:50:11,129 : INFO : PROGRESS: pass 1, dispatched chunk #0 = documents up to #2000/8000, outstanding queue size 1\n",
      "2018-03-08 18:50:11,486 : INFO : PROGRESS: pass 1, dispatched chunk #1 = documents up to #4000/8000, outstanding queue size 2\n",
      "2018-03-08 18:50:11,493 : INFO : PROGRESS: pass 1, dispatched chunk #2 = documents up to #6000/8000, outstanding queue size 3\n",
      "2018-03-08 18:50:11,500 : INFO : PROGRESS: pass 1, dispatched chunk #3 = documents up to #8000/8000, outstanding queue size 4\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/gensim/models/ldamodel.py:775: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n",
      "2018-03-08 18:50:15,733 : INFO : topic #7 (0.005): 0.010*\"whi\" + 0.008*\"doe\" + 0.007*\"like\" + 0.005*\"answer\" + 0.004*\"power\" + 0.004*\"relationship\" + 0.004*\"lose\" + 0.004*\"whi doe\" + 0.003*\"long\" + 0.003*\"use\"\n",
      "2018-03-08 18:50:15,734 : INFO : topic #180 (0.005): 0.007*\"best\" + 0.006*\"ani\" + 0.004*\"becom\" + 0.004*\"time\" + 0.004*\"climat\" + 0.004*\"india\" + 0.004*\"love\" + 0.004*\"similar\" + 0.004*\"prime\" + 0.004*\"doe\"\n",
      "2018-03-08 18:50:15,735 : INFO : topic #74 (0.005): 0.006*\"place\" + 0.006*\"doe\" + 0.005*\"whi\" + 0.005*\"like\" + 0.004*\"password\" + 0.003*\"trick\" + 0.003*\"ani\" + 0.003*\"base\" + 0.003*\"librari\" + 0.003*\"number\"\n",
      "2018-03-08 18:50:15,735 : INFO : topic #13 (0.005): 0.007*\"time\" + 0.006*\"whi\" + 0.006*\"best\" + 0.006*\"learn\" + 0.005*\"univers\" + 0.004*\"did\" + 0.004*\"improv\" + 0.003*\"parallel\" + 0.003*\"parallel univers\" + 0.003*\"make\"\n",
      "2018-03-08 18:50:15,736 : INFO : topic #143 (0.005): 0.008*\"best\" + 0.007*\"ani\" + 0.006*\"chines\" + 0.005*\"like\" + 0.005*\"whi\" + 0.004*\"state\" + 0.004*\"think\" + 0.004*\"mobil\" + 0.003*\"unit\" + 0.003*\"unit state\"\n",
      "2018-03-08 18:50:15,753 : INFO : topic diff=inf, rho=0.408248\n",
      "2018-03-08 18:50:17,768 : INFO : -12.135 per-word bound, 4498.9 perplexity estimate based on a held-out corpus of 2000 documents with 19612 words\n",
      "2018-03-08 18:50:17,775 : INFO : PROGRESS: pass 2, dispatched chunk #0 = documents up to #2000/8000, outstanding queue size 1\n",
      "2018-03-08 18:50:18,127 : INFO : PROGRESS: pass 2, dispatched chunk #1 = documents up to #4000/8000, outstanding queue size 2\n",
      "2018-03-08 18:50:18,133 : INFO : PROGRESS: pass 2, dispatched chunk #2 = documents up to #6000/8000, outstanding queue size 3\n",
      "2018-03-08 18:50:18,140 : INFO : PROGRESS: pass 2, dispatched chunk #3 = documents up to #8000/8000, outstanding queue size 4\n",
      "2018-03-08 18:50:22,222 : INFO : topic #8 (0.005): 0.009*\"person\" + 0.006*\"best\" + 0.005*\"happen\" + 0.005*\"way\" + 0.005*\"track\" + 0.004*\"hair\" + 0.004*\"thing\" + 0.004*\"thing happen\" + 0.003*\"use\" + 0.003*\"start\"\n",
      "2018-03-08 18:50:22,223 : INFO : topic #159 (0.005): 0.007*\"job\" + 0.006*\"whi\" + 0.006*\"make\" + 0.006*\"job interview\" + 0.006*\"interview\" + 0.005*\"wa\" + 0.005*\"make job\" + 0.005*\"interview process\" + 0.005*\"tip make\" + 0.005*\"tip\"\n",
      "2018-03-08 18:50:22,224 : INFO : topic #61 (0.005): 0.005*\"make\" + 0.005*\"differ\" + 0.005*\"run\" + 0.005*\"minut\" + 0.005*\"like\" + 0.004*\"weather\" + 0.003*\"bootcamp\" + 0.003*\"day\" + 0.003*\"increas\" + 0.003*\"walk minut\"\n",
      "2018-03-08 18:50:22,225 : INFO : topic #138 (0.005): 0.012*\"best\" + 0.009*\"whi\" + 0.005*\"best place\" + 0.004*\"place visit\" + 0.004*\"develop\" + 0.004*\"realiti\" + 0.004*\"doe\" + 0.004*\"visit\" + 0.004*\"place\" + 0.004*\"phd\"\n",
      "2018-03-08 18:50:22,225 : INFO : topic #180 (0.005): 0.007*\"best\" + 0.006*\"time\" + 0.006*\"ani\" + 0.005*\"climat\" + 0.005*\"becom\" + 0.004*\"unexpect thing\" + 0.004*\"visitor\" + 0.004*\"thing\" + 0.004*\"thing time\" + 0.004*\"notic\"\n",
      "2018-03-08 18:50:22,243 : INFO : topic diff=inf, rho=0.377964\n",
      "2018-03-08 18:50:24,241 : INFO : -12.026 per-word bound, 4171.0 perplexity estimate based on a held-out corpus of 2000 documents with 19612 words\n",
      "2018-03-08 18:50:24,249 : INFO : PROGRESS: pass 3, dispatched chunk #0 = documents up to #2000/8000, outstanding queue size 1\n",
      "2018-03-08 18:50:24,602 : INFO : PROGRESS: pass 3, dispatched chunk #1 = documents up to #4000/8000, outstanding queue size 2\n",
      "2018-03-08 18:50:24,609 : INFO : PROGRESS: pass 3, dispatched chunk #2 = documents up to #6000/8000, outstanding queue size 3\n",
      "2018-03-08 18:50:24,615 : INFO : PROGRESS: pass 3, dispatched chunk #3 = documents up to #8000/8000, outstanding queue size 4\n",
      "2018-03-08 18:50:28,969 : INFO : topic #199 (0.005): 0.010*\"learn\" + 0.008*\"differ\" + 0.005*\"india\" + 0.005*\"movi\" + 0.004*\"best\" + 0.003*\"whi\" + 0.003*\"friend\" + 0.003*\"christian\" + 0.003*\"imag\" + 0.003*\"world\"\n",
      "2018-03-08 18:50:28,970 : INFO : topic #115 (0.005): 0.005*\"way\" + 0.004*\"thing\" + 0.003*\"write\" + 0.003*\"exam\" + 0.003*\"chef\" + 0.003*\"weight\" + 0.003*\"need\" + 0.003*\"pasport\" + 0.003*\"nepali\" + 0.003*\"scienc\"\n",
      "2018-03-08 18:50:28,971 : INFO : topic #2 (0.005): 0.010*\"whi\" + 0.008*\"depress\" + 0.006*\"like\" + 0.005*\"feel\" + 0.004*\"ice\" + 0.004*\"think\" + 0.004*\"doe\" + 0.004*\"feel depress\" + 0.003*\"best\" + 0.003*\"matur\"\n",
      "2018-03-08 18:50:28,971 : INFO : topic #145 (0.005): 0.009*\"math\" + 0.007*\"ad\" + 0.005*\"whi\" + 0.005*\"math math\" + 0.004*\"wa\" + 0.004*\"trump\" + 0.003*\"youtub\" + 0.003*\"bake\" + 0.003*\"live\" + 0.003*\"myth\"\n",
      "2018-03-08 18:50:28,972 : INFO : topic #150 (0.005): 0.007*\"india\" + 0.005*\"best\" + 0.004*\"whi\" + 0.004*\"lewi\" + 0.004*\"dot\" + 0.004*\"determin\" + 0.004*\"dot structur\" + 0.004*\"lewi dot\" + 0.004*\"structur\" + 0.004*\"exampl\"\n",
      "2018-03-08 18:50:28,989 : INFO : topic diff=inf, rho=0.353553\n",
      "2018-03-08 18:50:30,980 : INFO : -11.938 per-word bound, 3923.0 perplexity estimate based on a held-out corpus of 2000 documents with 19612 words\n",
      "2018-03-08 18:50:30,988 : INFO : PROGRESS: pass 4, dispatched chunk #0 = documents up to #2000/8000, outstanding queue size 1\n",
      "2018-03-08 18:50:31,338 : INFO : PROGRESS: pass 4, dispatched chunk #1 = documents up to #4000/8000, outstanding queue size 2\n",
      "2018-03-08 18:50:31,345 : INFO : PROGRESS: pass 4, dispatched chunk #2 = documents up to #6000/8000, outstanding queue size 3\n",
      "2018-03-08 18:50:31,351 : INFO : PROGRESS: pass 4, dispatched chunk #3 = documents up to #8000/8000, outstanding queue size 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-08 18:50:35,528 : INFO : topic #197 (0.005): 0.006*\"good\" + 0.006*\"2016\" + 0.005*\"book\" + 0.003*\"think\" + 0.003*\"use\" + 0.003*\"import\" + 0.003*\"best\" + 0.003*\"intern\" + 0.003*\"song\" + 0.003*\"categori\"\n",
      "2018-03-08 18:50:35,529 : INFO : topic #191 (0.005): 0.010*\"use\" + 0.006*\"doe\" + 0.005*\"india\" + 0.004*\"day\" + 0.004*\"make\" + 0.004*\"iit use\" + 0.004*\"elect\" + 0.004*\"peopl\" + 0.004*\"iit\" + 0.004*\"busi\"\n",
      "2018-03-08 18:50:35,530 : INFO : topic #3 (0.005): 0.017*\"desert\" + 0.015*\"compar\" + 0.014*\"temperatur\" + 0.014*\"temperatur compar\" + 0.014*\"averag temperatur\" + 0.014*\"averag\" + 0.008*\"cold\" + 0.008*\"gobi desert\" + 0.008*\"desert averag\" + 0.008*\"gobi\"\n",
      "2018-03-08 18:50:35,531 : INFO : topic #44 (0.005): 0.005*\"ring\" + 0.005*\"peopl\" + 0.005*\"doesn\" + 0.005*\"knowledg\" + 0.004*\"make\" + 0.003*\"whi\" + 0.003*\"comput\" + 0.003*\"video\" + 0.003*\"lord\" + 0.003*\"want\"\n",
      "2018-03-08 18:50:35,532 : INFO : topic #5 (0.005): 0.013*\"taffi\" + 0.012*\"import\" + 0.012*\"whi\" + 0.012*\"taffi candi\" + 0.012*\"candi\" + 0.012*\"saltwat\" + 0.012*\"saltwat taffi\" + 0.011*\"candi import\" + 0.011*\"whi saltwat\" + 0.006*\"way\"\n",
      "2018-03-08 18:50:35,550 : INFO : topic diff=inf, rho=0.333333\n",
      "2018-03-08 18:50:37,749 : INFO : -11.857 per-word bound, 3708.9 perplexity estimate based on a held-out corpus of 2000 documents with 19612 words\n",
      "2018-03-08 18:50:37,757 : INFO : PROGRESS: pass 5, dispatched chunk #0 = documents up to #2000/8000, outstanding queue size 1\n",
      "2018-03-08 18:50:38,110 : INFO : PROGRESS: pass 5, dispatched chunk #1 = documents up to #4000/8000, outstanding queue size 2\n",
      "2018-03-08 18:50:38,117 : INFO : PROGRESS: pass 5, dispatched chunk #2 = documents up to #6000/8000, outstanding queue size 3\n",
      "2018-03-08 18:50:38,123 : INFO : PROGRESS: pass 5, dispatched chunk #3 = documents up to #8000/8000, outstanding queue size 4\n",
      "2018-03-08 18:50:42,414 : INFO : topic #124 (0.005): 0.007*\"doe\" + 0.005*\"whi\" + 0.005*\"india\" + 0.005*\"good\" + 0.004*\"start\" + 0.004*\"think\" + 0.004*\"peopl\" + 0.004*\"song\" + 0.003*\"new\" + 0.003*\"best\"\n",
      "2018-03-08 18:50:42,415 : INFO : topic #161 (0.005): 0.008*\"doe\" + 0.005*\"india\" + 0.005*\"like\" + 0.005*\"thi\" + 0.003*\"way\" + 0.003*\"best\" + 0.003*\"recent\" + 0.003*\"block\" + 0.003*\"iphon\" + 0.003*\"hike\"\n",
      "2018-03-08 18:50:42,416 : INFO : topic #85 (0.005): 0.009*\"whi\" + 0.006*\"pictur\" + 0.005*\"way\" + 0.004*\"use\" + 0.004*\"onlin\" + 0.004*\"celebr\" + 0.003*\"doe\" + 0.003*\"imag\" + 0.003*\"hi\" + 0.003*\"increas\"\n",
      "2018-03-08 18:50:42,416 : INFO : topic #136 (0.005): 0.010*\"whi\" + 0.008*\"doe\" + 0.006*\"pok\" + 0.006*\"pok mon\" + 0.006*\"mon\" + 0.005*\"make\" + 0.004*\"write\" + 0.004*\"english\" + 0.003*\"time\" + 0.003*\"best\"\n",
      "2018-03-08 18:50:42,417 : INFO : topic #194 (0.005): 0.008*\"whi\" + 0.005*\"year\" + 0.005*\"slit\" + 0.005*\"quora\" + 0.004*\"travel\" + 0.003*\"like\" + 0.003*\"world\" + 0.003*\"singl slit\" + 0.003*\"year old\" + 0.003*\"alway\"\n",
      "2018-03-08 18:50:42,435 : INFO : topic diff=inf, rho=0.316228\n",
      "2018-03-08 18:50:44,631 : INFO : -11.788 per-word bound, 3536.2 perplexity estimate based on a held-out corpus of 2000 documents with 19612 words\n",
      "2018-03-08 18:50:44,700 : INFO : PROGRESS: pass 6, dispatched chunk #0 = documents up to #2000/8000, outstanding queue size 1\n",
      "2018-03-08 18:50:45,054 : INFO : PROGRESS: pass 6, dispatched chunk #1 = documents up to #4000/8000, outstanding queue size 2\n",
      "2018-03-08 18:50:45,061 : INFO : PROGRESS: pass 6, dispatched chunk #2 = documents up to #6000/8000, outstanding queue size 3\n",
      "2018-03-08 18:50:45,068 : INFO : PROGRESS: pass 6, dispatched chunk #3 = documents up to #8000/8000, outstanding queue size 4\n",
      "2018-03-08 18:50:49,574 : INFO : topic #179 (0.005): 0.007*\"peopl\" + 0.007*\"like\" + 0.007*\"whi\" + 0.007*\"account\" + 0.006*\"facebook\" + 0.006*\"password\" + 0.005*\"win\" + 0.005*\"gmail account\" + 0.005*\"gmail\" + 0.005*\"log facebook\"\n",
      "2018-03-08 18:50:49,576 : INFO : topic #11 (0.005): 0.012*\"whi\" + 0.006*\"doe\" + 0.006*\"like\" + 0.005*\"birthday\" + 0.005*\"celebr\" + 0.004*\"know\" + 0.004*\"exampl\" + 0.004*\"ha\" + 0.004*\"stress\" + 0.004*\"celebr birthday\"\n",
      "2018-03-08 18:50:49,576 : INFO : topic #91 (0.005): 0.010*\"whi\" + 0.006*\"best\" + 0.005*\"use\" + 0.005*\"love\" + 0.004*\"india\" + 0.004*\"make\" + 0.004*\"like\" + 0.004*\"year\" + 0.004*\"peopl\" + 0.003*\"ani\"\n",
      "2018-03-08 18:50:49,577 : INFO : topic #29 (0.005): 0.028*\"best\" + 0.014*\"whi\" + 0.010*\"best way\" + 0.010*\"way\" + 0.007*\"book\" + 0.007*\"way lose\" + 0.006*\"lose\" + 0.005*\"weight\" + 0.005*\"peopl\" + 0.005*\"lose weight\"\n",
      "2018-03-08 18:50:49,578 : INFO : topic #2 (0.005): 0.009*\"whi\" + 0.009*\"depress\" + 0.006*\"like\" + 0.006*\"feel\" + 0.005*\"ice\" + 0.004*\"think\" + 0.004*\"feel depress\" + 0.004*\"doe\" + 0.003*\"day\" + 0.003*\"white\"\n",
      "2018-03-08 18:50:49,596 : INFO : topic diff=inf, rho=0.301511\n",
      "2018-03-08 18:50:51,705 : INFO : -11.726 per-word bound, 3387.1 perplexity estimate based on a held-out corpus of 2000 documents with 19612 words\n",
      "2018-03-08 18:50:51,713 : INFO : PROGRESS: pass 7, dispatched chunk #0 = documents up to #2000/8000, outstanding queue size 1\n",
      "2018-03-08 18:50:52,063 : INFO : PROGRESS: pass 7, dispatched chunk #1 = documents up to #4000/8000, outstanding queue size 2\n",
      "2018-03-08 18:50:52,070 : INFO : PROGRESS: pass 7, dispatched chunk #2 = documents up to #6000/8000, outstanding queue size 3\n",
      "2018-03-08 18:50:52,076 : INFO : PROGRESS: pass 7, dispatched chunk #3 = documents up to #8000/8000, outstanding queue size 4\n",
      "2018-03-08 18:50:56,412 : INFO : topic #75 (0.005): 0.006*\"whi\" + 0.006*\"anger\" + 0.005*\"control\" + 0.005*\"ha\" + 0.004*\"india\" + 0.004*\"rape\" + 0.004*\"boyfriend\" + 0.004*\"phone\" + 0.004*\"control anger\" + 0.004*\"way\"\n",
      "2018-03-08 18:50:56,413 : INFO : topic #25 (0.005): 0.011*\"whi\" + 0.006*\"doe\" + 0.006*\"time\" + 0.005*\"make\" + 0.005*\"attract\" + 0.004*\"wall\" + 0.004*\"fix\" + 0.004*\"describ citi\" + 0.004*\"auckland describ\" + 0.004*\"auckland\"\n",
      "2018-03-08 18:50:56,414 : INFO : topic #196 (0.005): 0.010*\"whi\" + 0.007*\"best\" + 0.007*\"india\" + 0.006*\"girl\" + 0.004*\"way\" + 0.004*\"differ\" + 0.004*\"account\" + 0.004*\"think\" + 0.004*\"age\" + 0.004*\"economi\"\n",
      "2018-03-08 18:50:56,414 : INFO : topic #189 (0.005): 0.007*\"doe\" + 0.006*\"best\" + 0.004*\"android\" + 0.004*\"prepar\" + 0.004*\"thi\" + 0.004*\"colleg\" + 0.003*\"like\" + 0.003*\"worth\" + 0.003*\"coast\" + 0.003*\"intellig\"\n",
      "2018-03-08 18:50:56,415 : INFO : topic #71 (0.005): 0.032*\"best\" + 0.020*\"phone\" + 0.016*\"best phone\" + 0.012*\"buy\" + 0.011*\"phone buy\" + 0.011*\"15000\" + 0.008*\"answer\" + 0.008*\"upvot\" + 0.008*\"quora\" + 0.008*\"inr\"\n",
      "2018-03-08 18:50:56,433 : INFO : topic diff=inf, rho=0.288675\n",
      "2018-03-08 18:50:58,633 : INFO : -11.673 per-word bound, 3265.0 perplexity estimate based on a held-out corpus of 2000 documents with 19612 words\n",
      "2018-03-08 18:50:58,641 : INFO : PROGRESS: pass 8, dispatched chunk #0 = documents up to #2000/8000, outstanding queue size 1\n",
      "2018-03-08 18:50:58,993 : INFO : PROGRESS: pass 8, dispatched chunk #1 = documents up to #4000/8000, outstanding queue size 2\n",
      "2018-03-08 18:50:59,000 : INFO : PROGRESS: pass 8, dispatched chunk #2 = documents up to #6000/8000, outstanding queue size 3\n",
      "2018-03-08 18:50:59,007 : INFO : PROGRESS: pass 8, dispatched chunk #3 = documents up to #8000/8000, outstanding queue size 4\n",
      "2018-03-08 18:51:03,134 : INFO : topic #166 (0.005): 0.020*\"major\" + 0.010*\"job\" + 0.009*\"weakest\" + 0.009*\"prospect\" + 0.009*\"major term\" + 0.009*\"strongest major\" + 0.009*\"strongest\" + 0.009*\"term job\" + 0.009*\"weakest major\" + 0.009*\"job prospect\"\n",
      "2018-03-08 18:51:03,135 : INFO : topic #33 (0.005): 0.005*\"work\" + 0.005*\"traffic\" + 0.005*\"morn\" + 0.004*\"budget\" + 0.003*\"best\" + 0.003*\"day\" + 0.003*\"want\" + 0.003*\"invest\" + 0.003*\"whi\" + 0.003*\"thing\"\n",
      "2018-03-08 18:51:03,136 : INFO : topic #112 (0.005): 0.041*\"book\" + 0.032*\"read\" + 0.015*\"book read\" + 0.015*\"best book\" + 0.012*\"best\" + 0.007*\"20\" + 0.006*\"read book\" + 0.006*\"whi\" + 0.004*\"2016\" + 0.004*\"gener\"\n",
      "2018-03-08 18:51:03,137 : INFO : topic #142 (0.005): 0.013*\"doe\" + 0.009*\"friend\" + 0.006*\"whi\" + 0.005*\"like\" + 0.005*\"differ\" + 0.004*\"wifi\" + 0.004*\"love\" + 0.004*\"friend friend\" + 0.004*\"best\" + 0.004*\"whi doe\"\n",
      "2018-03-08 18:51:03,138 : INFO : topic #129 (0.005): 0.011*\"whi\" + 0.006*\"make\" + 0.005*\"use\" + 0.005*\"way\" + 0.005*\"india\" + 0.005*\"chines\" + 0.003*\"spoke\" + 0.003*\"bicycl\" + 0.003*\"bicycl spoke\" + 0.003*\"whi bicycl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-08 18:51:03,155 : INFO : topic diff=inf, rho=0.277350\n",
      "2018-03-08 18:51:05,353 : INFO : -11.627 per-word bound, 3162.6 perplexity estimate based on a held-out corpus of 2000 documents with 19612 words\n",
      "2018-03-08 18:51:05,362 : INFO : PROGRESS: pass 9, dispatched chunk #0 = documents up to #2000/8000, outstanding queue size 1\n",
      "2018-03-08 18:51:05,726 : INFO : PROGRESS: pass 9, dispatched chunk #1 = documents up to #4000/8000, outstanding queue size 2\n",
      "2018-03-08 18:51:05,733 : INFO : PROGRESS: pass 9, dispatched chunk #2 = documents up to #6000/8000, outstanding queue size 3\n",
      "2018-03-08 18:51:05,740 : INFO : PROGRESS: pass 9, dispatched chunk #3 = documents up to #8000/8000, outstanding queue size 4\n",
      "2018-03-08 18:51:09,978 : INFO : topic #137 (0.005): 0.007*\"becom\" + 0.005*\"whi\" + 0.005*\"soccer player\" + 0.005*\"soccer\" + 0.005*\"player\" + 0.005*\"differ\" + 0.005*\"topic\" + 0.005*\"accept\" + 0.005*\"small\" + 0.005*\"busi\"\n",
      "2018-03-08 18:51:09,979 : INFO : topic #166 (0.005): 0.021*\"major\" + 0.011*\"job\" + 0.009*\"weakest\" + 0.009*\"prospect\" + 0.009*\"major term\" + 0.009*\"strongest major\" + 0.009*\"strongest\" + 0.009*\"term job\" + 0.009*\"weakest major\" + 0.009*\"job prospect\"\n",
      "2018-03-08 18:51:09,980 : INFO : topic #38 (0.005): 0.040*\"quora\" + 0.028*\"question\" + 0.018*\"question quora\" + 0.011*\"answer\" + 0.010*\"doe\" + 0.008*\"whi\" + 0.007*\"best\" + 0.006*\"ask\" + 0.006*\"coval\" + 0.006*\"bond\"\n",
      "2018-03-08 18:51:09,981 : INFO : topic #83 (0.005): 0.007*\"doe\" + 0.006*\"whi\" + 0.006*\"best\" + 0.005*\"way\" + 0.004*\"good\" + 0.004*\"differ\" + 0.004*\"ask\" + 0.004*\"write\" + 0.004*\"size\" + 0.004*\"need\"\n",
      "2018-03-08 18:51:09,982 : INFO : topic #108 (0.005): 0.043*\"lose\" + 0.043*\"weight\" + 0.035*\"lose weight\" + 0.012*\"whi\" + 0.012*\"doe\" + 0.008*\"mean\" + 0.006*\"energi\" + 0.006*\"weight fast\" + 0.006*\"fast\" + 0.005*\"infinit\"\n",
      "2018-03-08 18:51:09,999 : INFO : topic diff=inf, rho=0.267261\n",
      "2018-03-08 18:51:12,012 : INFO : -11.585 per-word bound, 3072.5 perplexity estimate based on a held-out corpus of 2000 documents with 19612 words\n"
     ]
    }
   ],
   "source": [
    "num_topics = 200\n",
    "lda = models.ldamulticore.LdaMulticore(\n",
    "    q1_train_corpus, id2word=id2word, num_topics=num_topics,\n",
    "    workers=7, passes=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_model = 'LDA(num_topics={})'.format(num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform q1, q2 into LDA space: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_train_lda = lda[q1_train_corpus]\n",
    "q2_train_lda = lda[q2_train_corpus]\n",
    "\n",
    "q1_test_lda = lda[q1_test_corpus]\n",
    "q2_test_lda = lda[q2_test_corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LR In Topics Space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lda = hstack((q1_train_lda.corpus.sparse.T, q2_train_lda.corpus.sparse.T))\n",
    "y_train_lda = is_dup_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_lda = len(y_train_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight='balanced', cv=3, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=8, penalty='l1',\n",
       "           random_state=19590209, refit=True, scoring=None, solver='saga',\n",
       "           tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_lda = LogisticRegressionCV(\n",
    "    penalty='l1',\n",
    "    dual=False,\n",
    "    Cs=10,\n",
    "    cv=3,\n",
    "    class_weight='balanced',\n",
    "    random_state=19590209,\n",
    "    solver='saga',\n",
    "    n_jobs=8,\n",
    "    #max_iter=1000\n",
    ")\n",
    "\n",
    "lr_lda.fit(X_train_lda, y_train_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = repr(lr_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline score, assume random guessing with ratio_1 probability for 1:\n",
    "accuracy_baseline = accuracy_score(\n",
    "    is_dup, \n",
    "    np.random.binomial(1, ratio_1, size=len(is_dup))\n",
    ")\n",
    "logloss_baseline = log_loss(\n",
    "    is_dup,\n",
    "    np.full_like(is_dup, ratio_1, dtype=np.float64)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_lda = hstack((q1_test_lda.corpus.sparse.T, q2_test_lda.corpus.sparse.T))\n",
    "y_test_lda = is_dup_test\n",
    "n_test_lda = len(y_test_lda)\n",
    "\n",
    "y_pred_lda = lr_lda.predict(X_test_lda)\n",
    "accuracy_lda = accuracy_score(y_test_lda, y_pred_lda)\n",
    "\n",
    "y_pred_proba_lda = lr_lda.predict_proba(X_test_lda)\n",
    "logloss_lda = log_loss(y_test_lda, y_pred_proba_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_pred_index_lda = np.argwhere(y_test_lda != y_pred_lda).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "audit_dir = 'data/audit'\n",
    "if not os.path.isdir(audit_dir):\n",
    "    os.makedirs(audit_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(accuracy, logloss, wrong_pred_index,\n",
    "                  wrong_guess_index=None, n_pred=0, \n",
    "                  n_guess=0, for_set='test', f=None):\n",
    "    print(\"Accuracy {} score = {:.03f}, baseline = {:.03f}, higher is better\".format(\n",
    "            for_set,\n",
    "            accuracy,\n",
    "            accuracy_baseline),\n",
    "        file=f\n",
    "    )\n",
    "    if logloss is not None:\n",
    "        print(\"Log loss {} score = {:.03f}, baseline = {:.03f}, lower is better\".format(\n",
    "            for_set,\n",
    "            logloss,\n",
    "            logloss_baseline),\n",
    "        file=f\n",
    "    )\n",
    "    if wrong_pred_index is not None:\n",
    "        print(\"Wrong {} predictions: {}/{} ({:.03f})\".format(\n",
    "                for_set,\n",
    "                len(wrong_pred_index), n_pred,\n",
    "                len(wrong_pred_index)/n_pred if n_pred else 0),\n",
    "            file=f\n",
    "        )\n",
    "    if wrong_guess_index is not None:\n",
    "        print(\"Wrong {} guesses: {}/{} ({:.03f})\".format(\n",
    "                for_set,\n",
    "                len(wrong_guess_index), n_guess,\n",
    "                len(wrong_guess_index)/n_guess if n_guess else 0),\n",
    "            file=f\n",
    "        )\n",
    "    print(file=f)\n",
    "          \n",
    "def wrong_pred(i, q1, q2, is_dup, y_pred, sim12=None, f=None):\n",
    "    print(\"Q1: {!r}\".format(q1[i]), file=f)\n",
    "    print(\"Q2: {!r}\".format(q2[i]), file=f)\n",
    "    print(\"is_dup={}, pred={}{}\".format(\n",
    "            is_dup[i], y_pred[i], \n",
    "            ', sim={:.03f}'.format(sim12[i]) if sim12 is not None else ''\n",
    "        ),\n",
    "        file=f  \n",
    "    )\n",
    "    print(file=f)\n",
    "    \n",
    "def print_mistakes(q1, q2, is_dup, y_pred, sim12=None,\n",
    "               wrong_pred_index=None, wrong_guess_index=None,\n",
    "               for_set='test', f=None):\n",
    "    if wrong_pred_index is not None:\n",
    "        print(\"Wrong {} predictions:\".format(for_set), file=f)\n",
    "        print(file=f)\n",
    "        for i in wrong_pred_index:\n",
    "            wrong_pred(i, q1, q2, is_dup, y_pred, sim12, f)\n",
    "        print(file=f)\n",
    "    if wrong_guess_index is not None:\n",
    "        print(\"Wrong {} guesses:\".format(for_set), file=f)\n",
    "        print(file=f)\n",
    "        for i in wrong_guess_index:\n",
    "            wrong_pred(i, q1, q2, is_dup, y_pred, sim12, f)\n",
    "        print(file=f)\n",
    "\n",
    "def audit_info(train_sz=None, test_sz=None, \n",
    "               word_vectorizer=None, nlp_model=None, classifier=None, f=None):\n",
    "    print(\"Time:       {}\".format(\n",
    "            time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(report_time))\n",
    "        ),\n",
    "        file=f\n",
    "    )\n",
    "    print(\"Train/Test: {}/{}\".format(train_sz, test_sz), file=f)\n",
    "    print(\"Vectorizer: {}\".format(word_vectorizer), file=f)\n",
    "    print(\"NLP Model:  {}\".format(nlp_model), file=f)\n",
    "    print(\"Classifier: {}\".format(classifier), file=f)\n",
    "    print(file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy test score = 0.672, baseline = 0.528, higher is better\n",
      "Log loss test score = 0.672, baseline = 0.659, lower is better\n",
      "Wrong test predictions: 655/2000 (0.328)\n",
      "\n",
      "Audit file = data/audit/audit-lda-lr-2018-03-08-18-59-00-2433.log.gz\n"
     ]
    }
   ],
   "source": [
    "print_results(accuracy_lda, logloss_lda, wrong_pred_index_lda, n_pred=n_test_lda)\n",
    "\n",
    "audit_file = '{}/audit-lda-lr-{}-{}.log.gz'.format(\n",
    "    audit_dir,\n",
    "    time.strftime('%Y-%m-%d-%H-%M-%S', time.localtime(report_time)),\n",
    "    os.getpid()\n",
    ")\n",
    "with gzip.open(audit_file, 'wt') as f:\n",
    "    audit_info(n_train_lda, n_test_lda, word_vectorizer, nlp_model, classifier, f=f)\n",
    "    print_results(accuracy_lda, logloss_lda, wrong_pred_index_lda, n_pred=n_test_lda, f=f)\n",
    "    print_mistakes(q1_test, q2_test, y_test_lda, y_pred_lda,\n",
    "                   wrong_pred_index=wrong_pred_index_lda, f=f)\n",
    "print(\"Audit file = {}\".format(audit_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate through the 2 lists and compute the cosine similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  gensim.matutils import cossim\n",
    "\n",
    "def cos_sim(v1, v2):\n",
    "    if not v1 or not v2:\n",
    "        return np.nan\n",
    "    return cossim(v1, v2)\n",
    "\n",
    "def cos_sim_list(q1_lda, q2_lda):\n",
    "    return np.array(list(map(lambda s: cos_sim(*s), zip(q1_lda, q2_lda))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim12_train = cos_sim_list(q1_train_lda, q2_train_lda)\n",
    "sim12_test = cos_sim_list(q1_test_lda, q2_test_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LR In Similarities Space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beware of NaN's:\n",
    "train_index = ~np.isnan(sim12_train)\n",
    "X_train_sim = sim12_train[train_index].reshape(-1, 1)\n",
    "y_train_sim = is_dup_train[train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight='balanced', cv=3, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=8, penalty='l1',\n",
       "           random_state=19590209, refit=True, scoring=None, solver='saga',\n",
       "           tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_lda_sim = LogisticRegressionCV(\n",
    "    penalty='l1',\n",
    "    dual=False,\n",
    "    Cs=10,\n",
    "    cv=3,\n",
    "    class_weight='balanced',\n",
    "    random_state=19590209,\n",
    "    solver='saga',\n",
    "    n_jobs=8,\n",
    ")\n",
    "\n",
    "lr_lda_sim.fit(X_train_sim, y_train_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = repr(lr_lda_sim) + ' for sim score'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If sim score cannot be computed then guess w/ a Bernoulli distribution \n",
    "# w/ ratio_1 probabilty:\n",
    "test_index_sim = ~np.isnan(sim12_test)\n",
    "\n",
    "X_test_sim = sim12_test[test_index_sim].reshape(-1, 1)\n",
    "y_test_sim = is_dup_test\n",
    "\n",
    "n_pred_sim = np.count_nonzero(test_index_sim)\n",
    "n_guess_sim = len(y_test_sim) - n_pred_sim\n",
    "\n",
    "y_pred_sim = np.zeros_like(y_test_sim)\n",
    "y_pred_sim[test_index_sim] = lr_lda_sim.predict(X_test_sim)\n",
    "y_pred_sim[~test_index_sim] = np.random.binomial(1, ratio_1, size=n_guess_sim)\n",
    "accuracy_sim = accuracy_score(y_test_sim, y_pred_sim)\n",
    "\n",
    "y_pred_proba_sim = np.full_like(y_test_sim, ratio_1, dtype=np.float64)\n",
    "y_pred_proba_sim[test_index_sim] = lr_lda_sim.predict_proba(X_test_sim)[:,1]\n",
    "logloss_sim = log_loss(y_test_sim, y_pred_proba_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_all_index_sim = y_test_sim != y_pred_sim\n",
    "wrong_pred_index_sim = np.argwhere(wrong_all_index_sim & test_index_sim).flatten()\n",
    "wrong_guess_index_sim = np.argwhere(wrong_all_index_sim & ~test_index_sim).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy test score = 0.626, baseline = 0.528, higher is better\n",
      "Log loss test score = 0.661, baseline = 0.659, lower is better\n",
      "Wrong test predictions: 739/1988 (0.372)\n",
      "Wrong test guesses: 8/12 (0.667)\n",
      "\n",
      "Audit file = data/audit/audit-lda-sim-lr-2018-03-08-18-59-14-2433.log.gz\n"
     ]
    }
   ],
   "source": [
    "print_results(accuracy_sim, logloss_sim, wrong_pred_index_sim,\n",
    "        wrong_guess_index_sim, n_pred_sim, n_guess_sim)\n",
    "\n",
    "audit_file = '{}/audit-lda-sim-lr-{}-{}.log.gz'.format(\n",
    "    audit_dir,\n",
    "    time.strftime('%Y-%m-%d-%H-%M-%S', time.localtime(report_time)),\n",
    "    os.getpid()\n",
    ")\n",
    "with gzip.open(audit_file, 'wt') as f:\n",
    "    audit_info(n_train_lda, n_test_lda, word_vectorizer, nlp_model, classifier, f=f)\n",
    "    print_results(accuracy_sim, logloss_sim, wrong_pred_index_sim,\n",
    "        wrong_guess_index_sim, n_pred_sim, n_guess_sim, f=f)\n",
    "    print_mistakes(q1_test, q2_test, y_test_sim, y_pred_sim, sim12_test,\n",
    "               wrong_pred_index_sim, wrong_guess_index_sim, f=f)\n",
    "\n",
    "print(\"Audit file = {}\".format(audit_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
