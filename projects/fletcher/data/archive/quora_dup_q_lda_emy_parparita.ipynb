{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Topic:** Kaggle Challenge [Quora Question Pairs](https://www.kaggle.com/c/quora-question-pairs/data)\n",
    "\n",
    "Which of the provided pairs of questions contain two questions with the same meaning? The ground truth is the set of labels that have been supplied by human experts. The ground truth labels are inherently subjective, as the true meaning of sentences can never be known with certainty. Human labeling is also a 'noisy' process, and reasonable people will disagree. As a result, the ground truth labels on this dataset should be taken to be 'informed' but not 100% accurate, and may include incorrect labeling. The labels, on the whole, represent a reasonable consensus, but this may often not be true on a case by case basis for individual items in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scores:**\n",
    "\n",
    " - log_loss: official competition score\n",
    " - accuracy: relevant in real life"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General workflow:**\n",
    "\n",
    "- load train data set\n",
    "- cleanup (NaN's, non-English)\n",
    "- tokenize\n",
    "- perform semantic indexing/analysis\n",
    "- compute similarity scores per pair\n",
    "- train a classification algorithm for score -> is duplicate prediction\n",
    "- compute scores for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import gzip\n",
    "import re\n",
    "\n",
    "# logging for gensim (set to INFO)\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %matplotlib inline\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    sns.set()\n",
    "except (NameError) as e:\n",
    "    print(\"{}: No matplotlib graphics\".format(e))\n",
    "    plt = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.utils import resample\n",
    "import sklearn.metrics.pairwise as smp\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-07 05:26:49,642 : INFO : 'pattern' package not found; tag filters are not available for English\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.4.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gensim\n",
    "from gensim import corpora, models, similarities, matutils, \\\n",
    "    __version__ as gensim_version\n",
    "gensim_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(381310, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the cleaned train set:\n",
    "clean_file = './data/quora/clean.csv.gz'\n",
    "df = pd.read_csv(clean_file, header=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "ratio_1 = df['is_duplicate'].mean()\n",
    "subset_size = -1 # 10000\n",
    "\n",
    "if subset_size > 0:\n",
    "    # Use a smaller sub-set to speed up the process; preserve the ratio\n",
    "    # of is_duplicate:\n",
    "    n_samples = min(subset_size, df.shape[0]-1)\n",
    "\n",
    "    n_samples_1 = int(ratio_1 * n_samples)\n",
    "    use_df = pd.concat([\n",
    "            shuffle(df[df['is_duplicate'] == 0], n_samples=(n_samples - n_samples_1)),\n",
    "            shuffle(df[df['is_duplicate'] == 1], n_samples=n_samples_1)\n",
    "        ],\n",
    "        ignore_index=True\n",
    "    )\n",
    "else:\n",
    "    use_df = df\n",
    "    \n",
    "use_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the questions and the target flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = use_df['question1'].values\n",
    "q2 = use_df['question2'].values\n",
    "is_dup = use_df['is_duplicate'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimal EDA, look for duplicate questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_unique, q1_unique_counts = \\\n",
    "    np.unique(q1, return_index=False, return_inverse=False, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_num_dups, q1_dups_dist = \\\n",
    "    np.unique(q1_unique_counts, return_index=False, return_inverse=False, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f502c6a56d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if plt:\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 4))\n",
    "    xticks = np.arange(q1_num_dups.min(), q1_num_dups.max()+1)\n",
    "\n",
    "    ax[0].bar(q1_num_dups, q1_dups_dist)\n",
    "    #ax[0].set_xticks(xticks)\n",
    "    ax[0].set_title(\"Duplicate Q1 Distribution\")\n",
    "    ax[0].set_xlabel(\"# Duplicates\")\n",
    "    ax[0].set_ylabel(\"Count\")\n",
    "\n",
    "    ax[1].bar(q1_num_dups, q1_dups_dist, log=True)\n",
    "    #ax[1].set_xticks(xticks)\n",
    "    ax[1].set_title(\"Duplicate Q1 Distribution (Log Scale)\")\n",
    "    ax[1].set_xlabel(\"# Duplicates\")\n",
    "    ax[1].set_ylabel(\"Count\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split 80/20 train/test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_train, q1_test, \\\n",
    "    q2_train, q2_test, \\\n",
    "    is_dup_train, is_dup_test = \\\n",
    "        train_test_split(q1, q2, is_dup, test_size=.2, stratify=is_dup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize the text; use both q1 and q2 (why? TBD):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "stemmer = nltk.stem.porter.PorterStemmer().stem\n",
    "\n",
    "def tokenizer(doc, min_len=2):\n",
    "    # Normalize case:\n",
    "    doc = doc.lower()\n",
    "    # Separate on non-alpha:\n",
    "    tokens = re.split(r'[^a-z0-9]+', doc)\n",
    "    # Return all the tokens len >= min_len, stemmed:\n",
    "    words = filter(lambda t: len(t) >= min_len, tokens)\n",
    "    if stemmer:\n",
    "        words = map(stemmer, words)\n",
    "    return list(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(\n",
    "    ngram_range=(1, 2), \n",
    "    stop_words=\"english\", \n",
    "    token_pattern=r'(?i)\\b[a-z]{2,}\\b', #words with >= 2 alpha chars,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "cvec.fit(np.concatenate((q1_train, q2_train)))\n",
    "id2word = dict((v, k) for k, v in cvec.vocabulary_.items())\n",
    "\n",
    "q1_train_tfidf = cvec.transform(q1_train)\n",
    "q1_train_corpus = matutils.Sparse2Corpus(q1_train_tfidf.transpose())\n",
    "\n",
    "q2_train_tfidf = cvec.transform(q2_train)\n",
    "q2_train_corpus = matutils.Sparse2Corpus(q2_train_tfidf.transpose())\n",
    "\n",
    "q1_test_tfidf = cvec.transform(q1_test)\n",
    "q1_test_corpus = matutils.Sparse2Corpus(q1_test_tfidf.transpose())\n",
    "\n",
    "q2_test_tfidf = cvec.transform(q2_test)\n",
    "q2_test_corpus = matutils.Sparse2Corpus(q2_test_tfidf.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectorizer = repr(cvec) + ' + custom tokenizer + stemmer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build LDA model on based on q1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-07 05:26:57,642 : INFO : using symmetric alpha at 0.002\n",
      "2018-03-07 05:26:57,643 : INFO : using symmetric eta at 0.002\n",
      "2018-03-07 05:26:57,649 : INFO : using serial LDA version on this node\n",
      "2018-03-07 05:27:01,913 : INFO : running online LDA training, 500 topics, 10 passes over the supplied corpus of 8000 documents, updating every 14000 documents, evaluating every ~8000 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2018-03-07 05:27:01,914 : INFO : training LDA model using 7 processes\n",
      "2018-03-07 05:27:01,953 : INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #2000/8000, outstanding queue size 1\n",
      "2018-03-07 05:27:02,499 : INFO : PROGRESS: pass 0, dispatched chunk #1 = documents up to #4000/8000, outstanding queue size 2\n",
      "2018-03-07 05:27:02,506 : INFO : PROGRESS: pass 0, dispatched chunk #2 = documents up to #6000/8000, outstanding queue size 3\n",
      "2018-03-07 05:27:02,513 : INFO : PROGRESS: pass 0, dispatched chunk #3 = documents up to #8000/8000, outstanding queue size 4\n",
      "2018-03-07 05:27:15,394 : INFO : topic #302 (0.002): 0.016*\"whi\" + 0.009*\"car\" + 0.009*\"girl\" + 0.009*\"compani\" + 0.005*\"doe\" + 0.004*\"alarm\" + 0.004*\"love person\" + 0.004*\"talk thi\" + 0.004*\"shakespear\" + 0.004*\"healthier\"\n",
      "2018-03-07 05:27:15,395 : INFO : topic #185 (0.002): 0.015*\"doe\" + 0.007*\"compani\" + 0.007*\"data\" + 0.007*\"cultur\" + 0.007*\"like\" + 0.006*\"park\" + 0.006*\"park brake\" + 0.006*\"drive\" + 0.005*\"brake\" + 0.005*\"good\"\n",
      "2018-03-07 05:27:15,396 : INFO : topic #79 (0.002): 0.018*\"whi\" + 0.007*\"year\" + 0.007*\"think\" + 0.007*\"quora\" + 0.007*\"differ\" + 0.007*\"know\" + 0.005*\"love\" + 0.005*\"state\" + 0.005*\"amend\" + 0.005*\"great\"\n",
      "2018-03-07 05:27:15,397 : INFO : topic #321 (0.002): 0.008*\"compani\" + 0.007*\"argu\" + 0.007*\"manufactur\" + 0.007*\"best\" + 0.007*\"india\" + 0.007*\"book\" + 0.007*\"neg\" + 0.007*\"stop\" + 0.007*\"effect\" + 0.006*\"whi\"\n",
      "2018-03-07 05:27:15,398 : INFO : topic #394 (0.002): 0.022*\"whi\" + 0.015*\"way\" + 0.014*\"happen\" + 0.008*\"best\" + 0.007*\"yahoo account\" + 0.007*\"yahoo\" + 0.007*\"account\" + 0.005*\"eat\" + 0.004*\"pokemon ranger\" + 0.004*\"class 12\"\n",
      "2018-03-07 05:27:15,444 : INFO : topic diff=492.957397, rho=1.000000\n",
      "2018-03-07 05:27:20,752 : INFO : -16.864 per-word bound, 119294.6 perplexity estimate based on a held-out corpus of 2000 documents with 19684 words\n",
      "2018-03-07 05:27:20,761 : INFO : PROGRESS: pass 1, dispatched chunk #0 = documents up to #2000/8000, outstanding queue size 1\n",
      "2018-03-07 05:27:21,311 : INFO : PROGRESS: pass 1, dispatched chunk #1 = documents up to #4000/8000, outstanding queue size 2\n",
      "2018-03-07 05:27:21,323 : INFO : PROGRESS: pass 1, dispatched chunk #2 = documents up to #6000/8000, outstanding queue size 3\n",
      "2018-03-07 05:27:21,334 : INFO : PROGRESS: pass 1, dispatched chunk #3 = documents up to #8000/8000, outstanding queue size 4\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/gensim/models/ldamodel.py:775: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n",
      "2018-03-07 05:27:31,906 : INFO : topic #247 (0.002): 0.007*\"invans\" + 0.007*\"kendrick\" + 0.006*\"write\" + 0.006*\"free\" + 0.005*\"email password\" + 0.005*\"rule play\" + 0.005*\"rule\" + 0.005*\"password\" + 0.005*\"play badminton\" + 0.005*\"snapchat\"\n",
      "2018-03-07 05:27:31,907 : INFO : topic #129 (0.002): 0.013*\"compar\" + 0.011*\"penalti\" + 0.007*\"servic\" + 0.007*\"rel\" + 0.007*\"taxi rel\" + 0.007*\"compar taxi\" + 0.007*\"car servic\" + 0.007*\"avail\" + 0.007*\"servic avail\" + 0.007*\"good compar\"\n",
      "2018-03-07 05:27:31,907 : INFO : topic #292 (0.002): 0.009*\"time\" + 0.007*\"whi\" + 0.006*\"limit\" + 0.006*\"becom\" + 0.006*\"doe\" + 0.006*\"tutor\" + 0.006*\"peopl\" + 0.006*\"reduc\" + 0.006*\"tummi\" + 0.006*\"battl\"\n",
      "2018-03-07 05:27:31,908 : INFO : topic #48 (0.002): 0.009*\"best\" + 0.009*\"way\" + 0.009*\"quora\" + 0.007*\"whi\" + 0.007*\"wa\" + 0.006*\"countri\" + 0.006*\"develop\" + 0.006*\"child\" + 0.006*\"song\" + 0.005*\"follow quora\"\n",
      "2018-03-07 05:27:31,909 : INFO : topic #66 (0.002): 0.007*\"120v\" + 0.007*\"good\" + 0.007*\"becom\" + 0.007*\"make\" + 0.005*\"iphon\" + 0.005*\"onli\" + 0.004*\"best\" + 0.004*\"rich\" + 0.004*\"becom rich\" + 0.004*\"thing\"\n",
      "2018-03-07 05:27:31,953 : INFO : topic diff=inf, rho=0.408248\n",
      "2018-03-07 05:27:36,945 : INFO : -16.607 per-word bound, 99783.8 perplexity estimate based on a held-out corpus of 2000 documents with 19684 words\n",
      "2018-03-07 05:27:36,953 : INFO : PROGRESS: pass 2, dispatched chunk #0 = documents up to #2000/8000, outstanding queue size 1\n",
      "2018-03-07 05:27:37,487 : INFO : PROGRESS: pass 2, dispatched chunk #1 = documents up to #4000/8000, outstanding queue size 2\n",
      "2018-03-07 05:27:37,494 : INFO : PROGRESS: pass 2, dispatched chunk #2 = documents up to #6000/8000, outstanding queue size 3\n",
      "2018-03-07 05:27:37,501 : INFO : PROGRESS: pass 2, dispatched chunk #3 = documents up to #8000/8000, outstanding queue size 4\n",
      "2018-03-07 05:27:48,584 : INFO : topic #44 (0.002): 0.012*\"watch\" + 0.009*\"occupi\" + 0.009*\"whi\" + 0.008*\"grade\" + 0.008*\"good\" + 0.007*\"win elect\" + 0.007*\"elect\" + 0.007*\"win\" + 0.007*\"sin\" + 0.006*\"hindi\"\n",
      "2018-03-07 05:27:48,585 : INFO : topic #59 (0.002): 0.013*\"sahara averag\" + 0.013*\"sahara\" + 0.012*\"temperatur\" + 0.012*\"temperatur compar\" + 0.012*\"averag\" + 0.012*\"compar\" + 0.012*\"averag temperatur\" + 0.012*\"desert\" + 0.010*\"manag\" + 0.008*\"bug\"\n",
      "2018-03-07 05:27:48,586 : INFO : topic #496 (0.002): 0.009*\"doe\" + 0.008*\"goa\" + 0.007*\"whi vote\" + 0.006*\"stay\" + 0.006*\"goa day\" + 0.006*\"itinerari\" + 0.006*\"travel itinerari\" + 0.006*\"travel\" + 0.006*\"itinerari goa\" + 0.006*\"best travel\"\n",
      "2018-03-07 05:27:48,587 : INFO : topic #11 (0.002): 0.014*\"differ\" + 0.013*\"presid\" + 0.009*\"district\" + 0.009*\"best\" + 0.008*\"vice presid\" + 0.008*\"vice\" + 0.008*\"die\" + 0.007*\"spiritu\" + 0.005*\"magistr\" + 0.005*\"district magistr\"\n",
      "2018-03-07 05:27:48,587 : INFO : topic #235 (0.002): 0.013*\"emot\" + 0.012*\"anger\" + 0.012*\"overcom\" + 0.009*\"exampl\" + 0.008*\"phone\" + 0.008*\"dure\" + 0.008*\"ha\" + 0.007*\"newspap\" + 0.005*\"mobil\" + 0.004*\"interview\"\n",
      "2018-03-07 05:27:48,633 : INFO : topic diff=inf, rho=0.377964\n",
      "2018-03-07 05:27:53,648 : INFO : -16.415 per-word bound, 87369.2 perplexity estimate based on a held-out corpus of 2000 documents with 19684 words\n",
      "2018-03-07 05:27:53,656 : INFO : PROGRESS: pass 3, dispatched chunk #0 = documents up to #2000/8000, outstanding queue size 1\n",
      "2018-03-07 05:27:54,198 : INFO : PROGRESS: pass 3, dispatched chunk #1 = documents up to #4000/8000, outstanding queue size 2\n",
      "2018-03-07 05:27:54,209 : INFO : PROGRESS: pass 3, dispatched chunk #2 = documents up to #6000/8000, outstanding queue size 3\n",
      "2018-03-07 05:27:54,220 : INFO : PROGRESS: pass 3, dispatched chunk #3 = documents up to #8000/8000, outstanding queue size 4\n",
      "2018-03-07 05:28:04,583 : INFO : topic #465 (0.002): 0.012*\"peopl\" + 0.007*\"wa\" + 0.006*\"make\" + 0.006*\"good\" + 0.006*\"use\" + 0.006*\"whi\" + 0.006*\"thing\" + 0.006*\"biotechnolog\" + 0.006*\"financi\" + 0.006*\"person financi\"\n",
      "2018-03-07 05:28:04,584 : INFO : topic #180 (0.002): 0.009*\"ani\" + 0.008*\"failur\" + 0.007*\"say\" + 0.007*\"magnitud\" + 0.007*\"rio olymp\" + 0.007*\"access\" + 0.007*\"olymp\" + 0.007*\"rio\" + 0.007*\"improv\" + 0.007*\"english\"\n",
      "2018-03-07 05:28:04,584 : INFO : topic #320 (0.002): 0.008*\"curb black\" + 0.008*\"new\" + 0.008*\"curb\" + 0.008*\"help curb\" + 0.008*\"2000 rupe\" + 0.008*\"2000\" + 0.007*\"new 2000\" + 0.007*\"demonet 500\" + 0.007*\"demonet\" + 0.007*\"introduc new\"\n",
      "2018-03-07 05:28:04,585 : INFO : topic #284 (0.002): 0.007*\"differ\" + 0.006*\"come\" + 0.006*\"good\" + 0.006*\"wa\" + 0.006*\"trump\" + 0.006*\"mean\" + 0.006*\"effect demonit\" + 0.006*\"effect\" + 0.006*\"demonit\" + 0.006*\"demonit 500\"\n",
      "2018-03-07 05:28:04,586 : INFO : topic #339 (0.002): 0.016*\"whi\" + 0.010*\"vit\" + 0.010*\"whi kill\" + 0.010*\"kill\" + 0.006*\"compound\" + 0.006*\"jet com\" + 0.006*\"like corpor\" + 0.006*\"water\" + 0.006*\"engin vit\" + 0.006*\"corpor\"\n",
      "2018-03-07 05:28:04,632 : INFO : topic diff=inf, rho=0.353553\n",
      "2018-03-07 05:28:09,842 : INFO : -16.251 per-word bound, 77977.6 perplexity estimate based on a held-out corpus of 2000 documents with 19684 words\n",
      "2018-03-07 05:28:09,851 : INFO : PROGRESS: pass 4, dispatched chunk #0 = documents up to #2000/8000, outstanding queue size 1\n",
      "2018-03-07 05:28:10,383 : INFO : PROGRESS: pass 4, dispatched chunk #1 = documents up to #4000/8000, outstanding queue size 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-07 05:28:10,391 : INFO : PROGRESS: pass 4, dispatched chunk #2 = documents up to #6000/8000, outstanding queue size 3\n",
      "2018-03-07 05:28:10,398 : INFO : PROGRESS: pass 4, dispatched chunk #3 = documents up to #8000/8000, outstanding queue size 4\n",
      "2018-03-07 05:28:21,013 : INFO : topic #396 (0.002): 0.008*\"remov\" + 0.008*\"doe\" + 0.008*\"3d\" + 0.007*\"use\" + 0.005*\"whi\" + 0.004*\"stupid\" + 0.004*\"rural\" + 0.004*\"death\" + 0.004*\"rural area\" + 0.004*\"music consid\"\n",
      "2018-03-07 05:28:21,014 : INFO : topic #290 (0.002): 0.010*\"energi\" + 0.010*\"african\" + 0.009*\"rich\" + 0.008*\"countri\" + 0.007*\"polar\" + 0.007*\"did\" + 0.007*\"doe\" + 0.007*\"expans\" + 0.007*\"way\" + 0.007*\"differ\"\n",
      "2018-03-07 05:28:21,015 : INFO : topic #255 (0.002): 0.014*\"best\" + 0.010*\"day\" + 0.010*\"visit\" + 0.008*\"men\" + 0.008*\"like\" + 0.007*\"complet\" + 0.007*\"goa\" + 0.007*\"car\" + 0.007*\"visit goa\" + 0.007*\"goa day\"\n",
      "2018-03-07 05:28:21,015 : INFO : topic #422 (0.002): 0.013*\"engin\" + 0.009*\"pune\" + 0.006*\"softwar engin\" + 0.006*\"travel\" + 0.006*\"citigroup pune\" + 0.006*\"travel abroad\" + 0.006*\"citigroup\" + 0.006*\"offic\" + 0.006*\"abroad\" + 0.006*\"softwar\"\n",
      "2018-03-07 05:28:21,016 : INFO : topic #268 (0.002): 0.017*\"countri\" + 0.011*\"best\" + 0.008*\"differ\" + 0.008*\"block\" + 0.008*\"overcom\" + 0.008*\"writer\" + 0.008*\"follow\" + 0.008*\"differ follow\" + 0.008*\"writer block\" + 0.008*\"overcom writer\"\n",
      "2018-03-07 05:28:21,060 : INFO : topic diff=inf, rho=0.333333\n",
      "2018-03-07 05:28:25,846 : INFO : -16.104 per-word bound, 70424.9 perplexity estimate based on a held-out corpus of 2000 documents with 19684 words\n",
      "2018-03-07 05:28:25,854 : INFO : PROGRESS: pass 5, dispatched chunk #0 = documents up to #2000/8000, outstanding queue size 1\n",
      "2018-03-07 05:28:26,394 : INFO : PROGRESS: pass 5, dispatched chunk #1 = documents up to #4000/8000, outstanding queue size 2\n",
      "2018-03-07 05:28:26,537 : INFO : PROGRESS: pass 5, dispatched chunk #2 = documents up to #6000/8000, outstanding queue size 3\n",
      "2018-03-07 05:28:26,548 : INFO : PROGRESS: pass 5, dispatched chunk #3 = documents up to #8000/8000, outstanding queue size 4\n",
      "2018-03-07 05:28:37,294 : INFO : topic #61 (0.002): 0.023*\"card\" + 0.019*\"credit card\" + 0.019*\"credit\" + 0.017*\"india\" + 0.011*\"best\" + 0.008*\"make\" + 0.008*\"whi\" + 0.008*\"habit\" + 0.005*\"time\" + 0.004*\"bet\"\n",
      "2018-03-07 05:28:37,296 : INFO : topic #127 (0.002): 0.025*\"whi\" + 0.007*\"use\" + 0.006*\"like\" + 0.006*\"did\" + 0.005*\"best\" + 0.005*\"screen\" + 0.005*\"load\" + 0.005*\"compani\" + 0.005*\"doe\" + 0.005*\"sale\"\n",
      "2018-03-07 05:28:37,297 : INFO : topic #22 (0.002): 0.009*\"whi\" + 0.006*\"video\" + 0.006*\"elector\" + 0.006*\"music\" + 0.006*\"plant\" + 0.006*\"play\" + 0.006*\"time\" + 0.006*\"etg\" + 0.006*\"answer etg\" + 0.006*\"answer\"\n",
      "2018-03-07 05:28:37,297 : INFO : topic #7 (0.002): 0.066*\"battl\" + 0.034*\"compar\" + 0.029*\"contrast\" + 0.029*\"compar contrast\" + 0.025*\"wa\" + 0.024*\"did\" + 0.023*\"thi\" + 0.021*\"somm did\" + 0.021*\"signific\" + 0.021*\"contrast battl\"\n",
      "2018-03-07 05:28:37,298 : INFO : topic #103 (0.002): 0.010*\"good\" + 0.009*\"attack\" + 0.009*\"raw egg\" + 0.009*\"raw\" + 0.009*\"egg\" + 0.005*\"make\" + 0.005*\"299 good\" + 0.005*\"299\" + 0.005*\"exampl\" + 0.005*\"project idea\"\n",
      "2018-03-07 05:28:37,342 : INFO : topic diff=inf, rho=0.316228\n",
      "2018-03-07 05:28:42,161 : INFO : -15.969 per-word bound, 64153.1 perplexity estimate based on a held-out corpus of 2000 documents with 19684 words\n",
      "2018-03-07 05:28:42,169 : INFO : PROGRESS: pass 6, dispatched chunk #0 = documents up to #2000/8000, outstanding queue size 1\n",
      "2018-03-07 05:28:42,702 : INFO : PROGRESS: pass 6, dispatched chunk #1 = documents up to #4000/8000, outstanding queue size 2\n",
      "2018-03-07 05:28:42,709 : INFO : PROGRESS: pass 6, dispatched chunk #2 = documents up to #6000/8000, outstanding queue size 3\n",
      "2018-03-07 05:28:42,716 : INFO : PROGRESS: pass 6, dispatched chunk #3 = documents up to #8000/8000, outstanding queue size 4\n",
      "2018-03-07 05:28:52,803 : INFO : topic #10 (0.002): 0.024*\"black\" + 0.023*\"black hole\" + 0.023*\"hole\" + 0.010*\"whi\" + 0.009*\"money\" + 0.009*\"matter\" + 0.009*\"manual\" + 0.009*\"place\" + 0.009*\"best place\" + 0.009*\"best\"\n",
      "2018-03-07 05:28:52,804 : INFO : topic #172 (0.002): 0.020*\"whi\" + 0.007*\"institut\" + 0.007*\"burn\" + 0.007*\"calori\" + 0.007*\"import\" + 0.007*\"shah\" + 0.007*\"thing\" + 0.007*\"know\" + 0.007*\"year\" + 0.007*\"peopl\"\n",
      "2018-03-07 05:28:52,805 : INFO : topic #492 (0.002): 0.010*\"best\" + 0.009*\"use\" + 0.006*\"whi\" + 0.006*\"speci\" + 0.006*\"desert\" + 0.006*\"got\" + 0.006*\"7lpa\" + 0.006*\"pakistan\" + 0.006*\"peopl\" + 0.006*\"india\"\n",
      "2018-03-07 05:28:52,806 : INFO : topic #253 (0.002): 0.013*\"best\" + 0.009*\"strangest\" + 0.009*\"floor\" + 0.008*\"phone\" + 0.005*\"whi\" + 0.005*\"layer titan\" + 0.005*\"best smart\" + 0.005*\"review\" + 0.005*\"remot beta\" + 0.005*\"fast\"\n",
      "2018-03-07 05:28:52,807 : INFO : topic #12 (0.002): 0.016*\"whi\" + 0.010*\"rang\" + 0.010*\"dynam rang\" + 0.010*\"dynam\" + 0.007*\"need\" + 0.007*\"doe\" + 0.007*\"differ\" + 0.006*\"day\" + 0.006*\"cost\" + 0.006*\"averag\"\n",
      "2018-03-07 05:28:52,854 : INFO : topic diff=inf, rho=0.301511\n",
      "2018-03-07 05:28:57,654 : INFO : -15.851 per-word bound, 59114.1 perplexity estimate based on a held-out corpus of 2000 documents with 19684 words\n",
      "2018-03-07 05:28:57,663 : INFO : PROGRESS: pass 7, dispatched chunk #0 = documents up to #2000/8000, outstanding queue size 1\n",
      "2018-03-07 05:28:58,198 : INFO : PROGRESS: pass 7, dispatched chunk #1 = documents up to #4000/8000, outstanding queue size 2\n",
      "2018-03-07 05:28:58,205 : INFO : PROGRESS: pass 7, dispatched chunk #2 = documents up to #6000/8000, outstanding queue size 3\n",
      "2018-03-07 05:28:58,212 : INFO : PROGRESS: pass 7, dispatched chunk #3 = documents up to #8000/8000, outstanding queue size 4\n",
      "2018-03-07 05:29:08,255 : INFO : topic #35 (0.002): 0.012*\"sleep\" + 0.008*\"indian\" + 0.008*\"whi\" + 0.008*\"ear\" + 0.008*\"better\" + 0.008*\"cigarett\" + 0.004*\"peopl\" + 0.004*\"cigarett whi\" + 0.004*\"wors\" + 0.004*\"curli hair\"\n",
      "2018-03-07 05:29:08,256 : INFO : topic #1 (0.002): 0.019*\"monday\" + 0.014*\"charg\" + 0.009*\"possibl\" + 0.009*\"qualit\" + 0.009*\"wed\" + 0.005*\"best\" + 0.005*\"confer\" + 0.005*\"follow monday\" + 0.005*\"anoth region\" + 0.005*\"current monday\"\n",
      "2018-03-07 05:29:08,257 : INFO : topic #295 (0.002): 0.011*\"doe\" + 0.008*\"manag\" + 0.008*\"start\" + 0.008*\"need\" + 0.007*\"cat\" + 0.007*\"weight month\" + 0.004*\"month\" + 0.004*\"free\" + 0.004*\"best\" + 0.004*\"game onlin\"\n",
      "2018-03-07 05:29:08,258 : INFO : topic #59 (0.002): 0.021*\"sahara averag\" + 0.021*\"sahara\" + 0.019*\"temperatur\" + 0.019*\"temperatur compar\" + 0.019*\"averag\" + 0.019*\"compar\" + 0.019*\"averag temperatur\" + 0.018*\"desert\" + 0.009*\"manag\" + 0.009*\"taklamakan desert\"\n",
      "2018-03-07 05:29:08,259 : INFO : topic #88 (0.002): 0.016*\"belli\" + 0.016*\"fat\" + 0.015*\"belli fat\" + 0.012*\"topic\" + 0.012*\"topic quora\" + 0.012*\"quora\" + 0.012*\"cycl\" + 0.011*\"follow\" + 0.011*\"follow topic\" + 0.008*\"reduc belli\"\n",
      "2018-03-07 05:29:08,304 : INFO : topic diff=inf, rho=0.288675\n",
      "2018-03-07 05:29:13,091 : INFO : -15.741 per-word bound, 54753.2 perplexity estimate based on a held-out corpus of 2000 documents with 19684 words\n",
      "2018-03-07 05:29:13,100 : INFO : PROGRESS: pass 8, dispatched chunk #0 = documents up to #2000/8000, outstanding queue size 1\n",
      "2018-03-07 05:29:13,304 : INFO : PROGRESS: pass 8, dispatched chunk #1 = documents up to #4000/8000, outstanding queue size 2\n",
      "2018-03-07 05:29:13,640 : INFO : PROGRESS: pass 8, dispatched chunk #2 = documents up to #6000/8000, outstanding queue size 3\n",
      "2018-03-07 05:29:13,647 : INFO : PROGRESS: pass 8, dispatched chunk #3 = documents up to #8000/8000, outstanding queue size 4\n",
      "2018-03-07 05:29:24,023 : INFO : topic #490 (0.002): 0.013*\"learn\" + 0.013*\"best\" + 0.009*\"institut\" + 0.006*\"school\" + 0.006*\"whi\" + 0.006*\"hi\" + 0.006*\"learn german\" + 0.006*\"german\" + 0.006*\"like\" + 0.006*\"learn python\"\n",
      "2018-03-07 05:29:24,025 : INFO : topic #250 (0.002): 0.025*\"way lose\" + 0.016*\"fastest\" + 0.012*\"time\" + 0.012*\"stone\" + 0.012*\"fastest way\" + 0.011*\"pound\" + 0.009*\"lose\" + 0.008*\"state ani\" + 0.008*\"person unit\" + 0.008*\"ani given\"\n",
      "2018-03-07 05:29:24,025 : INFO : topic #353 (0.002): 0.008*\"differ\" + 0.008*\"brain\" + 0.008*\"resist\" + 0.007*\"whi\" + 0.005*\"doe\" + 0.005*\"know\" + 0.005*\"hi\" + 0.005*\"word\" + 0.005*\"long\" + 0.005*\"rel\"\n",
      "2018-03-07 05:29:24,026 : INFO : topic #315 (0.002): 0.011*\"impress\" + 0.008*\"inch\" + 0.008*\"streak\" + 0.008*\"paper\" + 0.008*\"husband\" + 0.008*\"impress girl\" + 0.008*\"girl\" + 0.008*\"attitud\" + 0.008*\"waist\" + 0.008*\"expect\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-07 05:29:24,027 : INFO : topic #60 (0.002): 0.020*\"whi\" + 0.015*\"post\" + 0.010*\"naruto\" + 0.007*\"did\" + 0.007*\"theme\" + 0.007*\"episod\" + 0.007*\"relat\" + 0.007*\"relat episod\" + 0.007*\"anim\" + 0.007*\"episod naruto\"\n",
      "2018-03-07 05:29:24,072 : INFO : topic diff=inf, rho=0.277350\n",
      "2018-03-07 05:29:29,092 : INFO : -15.640 per-word bound, 51071.7 perplexity estimate based on a held-out corpus of 2000 documents with 19684 words\n",
      "2018-03-07 05:29:29,100 : INFO : PROGRESS: pass 9, dispatched chunk #0 = documents up to #2000/8000, outstanding queue size 1\n",
      "2018-03-07 05:29:29,638 : INFO : PROGRESS: pass 9, dispatched chunk #1 = documents up to #4000/8000, outstanding queue size 2\n",
      "2018-03-07 05:29:29,645 : INFO : PROGRESS: pass 9, dispatched chunk #2 = documents up to #6000/8000, outstanding queue size 3\n",
      "2018-03-07 05:29:29,652 : INFO : PROGRESS: pass 9, dispatched chunk #3 = documents up to #8000/8000, outstanding queue size 4\n",
      "2018-03-07 05:29:39,444 : INFO : topic #5 (0.002): 0.015*\"date\" + 0.014*\"like\" + 0.010*\"true\" + 0.010*\"stori\" + 0.010*\"true stori\" + 0.008*\"happen\" + 0.008*\"ha\" + 0.008*\"krishna\" + 0.008*\"wa\" + 0.008*\"base true\"\n",
      "2018-03-07 05:29:39,445 : INFO : topic #232 (0.002): 0.013*\"peopl\" + 0.007*\"doe\" + 0.007*\"main\" + 0.007*\"non\" + 0.007*\"dr\" + 0.006*\"open\" + 0.006*\"github\" + 0.006*\"contribut\" + 0.006*\"whi\" + 0.004*\"india\"\n",
      "2018-03-07 05:29:39,446 : INFO : topic #240 (0.002): 0.012*\"way\" + 0.006*\"best\" + 0.006*\"differ\" + 0.006*\"doe\" + 0.006*\"govern\" + 0.006*\"backlog\" + 0.006*\"like\" + 0.006*\"right way\" + 0.006*\"right\" + 0.005*\"girlfriend\"\n",
      "2018-03-07 05:29:39,446 : INFO : topic #173 (0.002): 0.013*\"learn\" + 0.005*\"game develop\" + 0.005*\"develop\" + 0.005*\"game\" + 0.005*\"exist\" + 0.005*\"exist god\" + 0.005*\"god\" + 0.005*\"matlab necessari\" + 0.005*\"armi doctor\" + 0.005*\"matlab\"\n",
      "2018-03-07 05:29:39,447 : INFO : topic #281 (0.002): 0.009*\"whi\" + 0.009*\"life\" + 0.009*\"war\" + 0.008*\"file edit\" + 0.008*\"file\" + 0.008*\"convert pdf\" + 0.008*\"edit\" + 0.008*\"edit indesign\" + 0.008*\"indd file\" + 0.008*\"indd\"\n",
      "2018-03-07 05:29:39,492 : INFO : topic diff=inf, rho=0.267261\n",
      "2018-03-07 05:29:44,377 : INFO : -15.550 per-word bound, 47980.6 perplexity estimate based on a held-out corpus of 2000 documents with 19684 words\n"
     ]
    }
   ],
   "source": [
    "num_topics = 100\n",
    "lda = models.ldamulticore.LdaMulticore(\n",
    "    q1_train_corpus, id2word=id2word, num_topics=num_topics,\n",
    "    workers=7, passes=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_model = 'LDA(num_topics={})'.format(num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform q1, q2 into LDA space: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_train_lda = lda[q1_train_corpus]\n",
    "q2_train_lda = lda[q2_train_corpus]\n",
    "\n",
    "q1_test_lda = lda[q1_test_corpus]\n",
    "q2_test_lda = lda[q2_test_corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate through the 2 lists and compute the cosine similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  gensim.matutils import cossim\n",
    "\n",
    "def cos_sim(v1, v2):\n",
    "    if not v1 or not v2:\n",
    "        return np.nan\n",
    "    return cossim(v1, v2)\n",
    "\n",
    "def cos_sim_list(q1_lda, q2_lda):\n",
    "    return np.array(list(map(lambda s: cos_sim(*s), zip(q1_lda, q2_lda))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim12_train = cos_sim_list(q1_train_lda, q2_train_lda)\n",
    "sim12_test = cos_sim_list(q1_test_lda, q2_test_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use K Nearest Neighbors to map similarities into is_dup labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beware of NaN's:\n",
    "train_index = ~np.isnan(sim12_train)\n",
    "X_train = sim12_train[train_index].reshape(-1, 1)\n",
    "y_train = is_dup_train[train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=500, p=1,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knc = KNeighborsClassifier(n_neighbors=500, p=1)\n",
    "knc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = repr(knc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "\n",
    "# Baseline score, assume random guessing with ratio_1 probability for 1:\n",
    "accuracy_baseline = accuracy_score(\n",
    "    is_dup, \n",
    "    np.random.binomial(1, ratio_1, size=len(is_dup))\n",
    ")\n",
    "logloss_baseline = log_loss(\n",
    "    is_dup,\n",
    "    np.full_like(is_dup, ratio_1, dtype=np.float64)\n",
    ")\n",
    "\n",
    "def compile_results(X, y_true, estimator):\n",
    "    # Beware of NaN's in X:\n",
    "    non_nan_index = ~np.isnan(X)\n",
    "    n_pred = np.count_nonzero(non_nan_index)\n",
    "    n_guess = len(non_nan_index) - n_pred\n",
    "    X_pred = X[non_nan_index].reshape(-1, 1)\n",
    "\n",
    "    y_pred = np.zeros_like(y_true)\n",
    "    y_pred[non_nan_index] = estimator.predict(X_pred)\n",
    "    y_pred[~non_nan_index] = np.random.binomial(1, ratio_1, size=n_guess)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    if hasattr(estimator, 'predict_proba'):\n",
    "        y_pred_proba = np.full_like(y_true, ratio_1, dtype=np.float64)\n",
    "        y_pred_proba[non_nan_index] = estimator.predict_proba(X_pred)[:,1]\n",
    "        logloss = log_loss(y_true, y_pred_proba)\n",
    "    else:\n",
    "        logloss = None\n",
    "    \n",
    "    wrong_index = y_true != y_pred\n",
    "    wrong_pred_index = np.argwhere(wrong_index & non_nan_index).flatten()\n",
    "    wrong_guess_index = np.argwhere(wrong_index & ~non_nan_index).flatten()\n",
    "\n",
    "    return accuracy, logloss, y_pred, wrong_pred_index, wrong_guess_index, n_pred, n_guess\n",
    "\n",
    "def print_results(accuracy, logloss, wrong_pred_index, \n",
    "                  wrong_guess_index, n_pred, n_guess, for_set='test', f=None):\n",
    "    print(\"Accuracy {} score = {:.03f}, baseline = {:.03f}, higher is better\".format(\n",
    "            for_set,\n",
    "            accuracy,\n",
    "            accuracy_baseline),\n",
    "        file=f\n",
    "    )\n",
    "    if logloss is not None:\n",
    "        print(\"Log loss {} score = {:.03f}, baseline = {:.03f}, lower is better\".format(\n",
    "            for_set,\n",
    "            logloss,\n",
    "            logloss_baseline),\n",
    "        file=f\n",
    "    )\n",
    "    print(\"Wrong {} predictions: {}/{} ({:.03f})\".format(\n",
    "            for_set,\n",
    "            len(wrong_pred_index), n_pred,\n",
    "            len(wrong_pred_index)/n_pred if n_pred else 0),\n",
    "        file=f\n",
    "    )\n",
    "    print(\"Wrong {} guesses: {}/{} ({:.03f})\".format(\n",
    "            for_set,\n",
    "            len(wrong_guess_index), n_guess,\n",
    "            len(wrong_guess_index)/n_guess if n_guess else 0),\n",
    "        file=f\n",
    "    )\n",
    "    print(file=f)\n",
    "          \n",
    "def wrong_pred(i, q1, q2, is_dup, y_pred, sim12, f=None):\n",
    "    print(\"Q1: {!r}\".format(q1[i]), file=f)\n",
    "    print(\"Q2: {!r}\".format(q2[i]), file=f)\n",
    "    print(\"is_dup={}, pred={}, sim={:.03f}\".format(\n",
    "            is_dup[i], y_pred[i], sim12[i]\n",
    "        ),\n",
    "        file=f  \n",
    "    )\n",
    "    print(file=f)\n",
    "    \n",
    "def print_mistakes(q1, q2, is_dup, y_pred, sim12,\n",
    "               wrong_pred_index, wrong_guess_index,\n",
    "               for_set='test', f=None):\n",
    "    print(\"Wrong {} predictions:\".format(for_set), file=f)\n",
    "    print(file=f)\n",
    "    for i in wrong_pred_index:\n",
    "        wrong_pred(i, q1, q2, is_dup, y_pred, sim12, f)\n",
    "    print(file=f)\n",
    "    print(\"Wrong {} guesses:\".format(for_set), file=f)\n",
    "    print(file=f)\n",
    "\n",
    "    for i in wrong_guess_index:\n",
    "        wrong_pred(i, q1, q2, is_dup, y_pred, sim12, f)\n",
    "    print(file=f)\n",
    "       \n",
    "def audit_info(train_sz=None, test_sz=None, \n",
    "               word_vectorizer=None, nlp_model=None, classifier=None, f=None):\n",
    "    print(\"Time:       {}\".format(\n",
    "            time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(report_time))\n",
    "        ),\n",
    "        file=f\n",
    "    )\n",
    "    print(\"Train/Test: {}/{}\".format(train_sz, test_sz), file=f)\n",
    "    print(\"Vectorizer: {}\".format(word_vectorizer), file=f)\n",
    "    print(\"NLP Model:  {}\".format(nlp_model), file=f)\n",
    "    print(\"Classifier: {}\".format(classifier), file=f)\n",
    "    print(file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_time = time.time()\n",
    "\n",
    "accuracy_test, logloss_test, y_pred_test, wrong_pred_index_test, \\\n",
    "    wrong_guess_index_test, n_pred_test, n_guess_test = \\\n",
    "        compile_results(sim12_test, is_dup_test, knc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy test score = 0.623, baseline = 0.530, higher is better\n",
      "Log loss test score = 0.631, baseline = 0.659, lower is better\n",
      "Wrong test predictions: 749/1985 (0.377)\n",
      "Wrong test guesses: 6/15 (0.400)\n",
      "\n",
      "Audit file = data/quora/audit-2018-03-07-05-30-21-3652.log.gz\n"
     ]
    }
   ],
   "source": [
    "print_results(accuracy_test, logloss_test, wrong_pred_index_test,\n",
    "        wrong_guess_index_test, n_pred_test, n_guess_test)\n",
    "\n",
    "audit_file = 'data/quora/audit-{}-{}.log.gz'.format(\n",
    "    time.strftime('%Y-%m-%d-%H-%M-%S', time.localtime(report_time)),\n",
    "    os.getpid()\n",
    ")\n",
    "with gzip.open(audit_file, 'wt') as f:\n",
    "    audit_info(\n",
    "        len(is_dup_train), len(is_dup_test),\n",
    "        word_vectorizer, nlp_model, classifier, f=f)\n",
    "    print_results(accuracy_test, logloss_test, wrong_pred_index_test,\n",
    "        wrong_guess_index_test, n_pred_test, n_guess_test, f=f)\n",
    "    print_mistakes(q1_test, q2_test, is_dup_test, y_pred_test, sim12_test,\n",
    "               wrong_pred_index_test, wrong_guess_index_test, f=f)\n",
    "\n",
    "print(\"Audit file = {}\".format(audit_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
