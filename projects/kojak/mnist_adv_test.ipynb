{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MNIST Adversarial Test**  \n",
    "Run advesarial attack on a given model using a defense strategy and save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import itertools\n",
    "import re\n",
    "import pprint\n",
    "import pickle\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    %matplotlib inline\n",
    "    plot_ok = True\n",
    "except (NameError) as e:\n",
    "    print(\"{}: Running without plotting\".format(e), file=sys.stderr)\n",
    "    plot_ok = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_FILE = 'data/mnist/adv_set-0.100-0.400-0-60000-0-10000.npz'\n",
    "USE_P = .1\n",
    "TRAIN_ADV_P = 0\n",
    "TEST_DISPLAY = False\n",
    "MNIST_SHAPE = 28, 28\n",
    "FIGSIZE = 4\n",
    "LOG_DIR = 'logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import noise_utils\n",
    "import pil_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten_x(X):\n",
    "    return np.array([img.flatten() for img in X])\n",
    "\n",
    "def build_y(Y):\n",
    "    return np.argwhere(Y)[:,1]\n",
    "\n",
    "def plot_x(x, y=None, x_adv=None):    \n",
    "    if x_adv is not None:\n",
    "        fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(FIGSIZE*2, FIGSIZE))\n",
    "        axs = axs.flatten()\n",
    "        pil_utils.plot_image(x.reshape(MNIST_SHAPE), title='{} - Org'.format(y), ax=axs[0])\n",
    "        pil_utils.plot_image(x_adv.reshape(MNIST_SHAPE), title='{} - Adv'.format(y), ax=axs[1])\n",
    "    else:\n",
    "        pil_utils.plot_image(x.reshape(MNIST_SHAPE), title=y)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pct_data(x, y, p=1):\n",
    "    if p < 0 or p >= 1.:\n",
    "        return x, y\n",
    "    n = len(x)\n",
    "    size = int(n * p)\n",
    "    index = np.random.choice(np.arange(n), size, replace=False)\n",
    "    return x[index], y[index]    \n",
    "\n",
    "\n",
    "def load_data(data_file=DATA_FILE, use_p=USE_P, train_adv_p=TRAIN_ADV_P):\n",
    "    npzfile = np.load(data_file)\n",
    "    X_train = flatten_x(npzfile['X_train'])\n",
    "    Y_train = build_y(npzfile['Y_train'])\n",
    "    X_test = flatten_x(npzfile['X_test'])\n",
    "    Y_test = build_y(npzfile['Y_test'])\n",
    "    X_train_adv = flatten_x(npzfile['X_train_adv'])\n",
    "    X_test_adv = flatten_x(npzfile['X_test_adv'])\n",
    "    accuracy_bbox, accuracy_bbox_adv = npzfile['accuracies']\n",
    "    lmbda, eps = npzfile['flags']\n",
    "\n",
    "    if plot_ok and TEST_DISPLAY:\n",
    "        for i in np.random.choice(np.arange(len(X_train)), 100, replace=False):\n",
    "            clear_output()\n",
    "            plot_x(X_train[i], Y_train[i], X_train_adv[i])\n",
    "            time.sleep(2)\n",
    "\n",
    "    if plot_ok and TEST_DISPLAY:\n",
    "        for i in np.random.choice(np.arange(len(X_test)), 100, replace=False):\n",
    "            clear_output()\n",
    "            plot_x(X_test[i], Y_test[i], X_test_adv[i])\n",
    "            time.sleep(2)\n",
    "\n",
    "    if 0 < use_p and use_p < 1.:\n",
    "        from sklearn.model_selection import \\\n",
    "            StratifiedShuffleSplit\n",
    "\n",
    "        sss = StratifiedShuffleSplit(n_splits=1, test_size=use_p, random_state=19590209)\n",
    "        for _, train_index in sss.split(X_train, Y_train):\n",
    "            x_train, y_train, x_train_adv = \\\n",
    "                X_train[train_index], Y_train[train_index], X_train_adv[train_index]\n",
    "            break\n",
    "\n",
    "        for _, test_index in sss.split(X_test, Y_test):   \n",
    "            x_test, y_test, x_test_adv = \\\n",
    "                X_test[test_index], Y_test[test_index], X_test_adv[test_index]\n",
    "            break\n",
    "    else:\n",
    "        x_train, y_train, x_train_adv = X_train, Y_train, X_train_adv\n",
    "        x_test, y_test, x_test_adv = \\\n",
    "            X_test, Y_test, X_test_adv\n",
    "    print(\"x_train={}, x_test={}\".format(x_train.shape, x_test.shape))\n",
    "\n",
    "    if train_adv_p > 0:\n",
    "        print(\"Adding {:.02f}% adv to training\".format(train_adv_p * 100))\n",
    "        xtra_train_x, xtra_train_y = get_pct_data(x_train_adv, y_train, train_adv_p)\n",
    "        x_train = np.vstack((x_train, xtra_train_x))\n",
    "        y_train = np.hstack((y_train, xtra_train_y))\n",
    "        print(\"x_train={}, y_train={}\".format(x_train.shape, y_train.shape))\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "    return x_train, y_train, x_test, y_test, x_test_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import \\\n",
    "    accuracy_score, confusion_matrix\n",
    "\n",
    "def make_noise_set(x, noiser, **noise_args):\n",
    "    return np.array([noiser(flatten_img.reshape(MNIST_SHAPE), **noise_args).flatten()\n",
    "                     for flatten_img in x])\n",
    "\n",
    "def get_noiser_info(noiser, noise_args):\n",
    "    info = getattr(noiser, '__name__', 'None')\n",
    "    if noiser and noise_args:\n",
    "        args = '('\n",
    "        for k, v in sorted(noise_args.items()):\n",
    "            if args != '(':\n",
    "                args += ', '\n",
    "            args += '{}={!r}'.format(k, v)\n",
    "        args += ')'\n",
    "        info += args\n",
    "    return info\n",
    "\n",
    "\n",
    "def try_one(estimator, \n",
    "            x_train, y_train,\n",
    "            x_test, y_test, x_test_adv=None,\n",
    "            train_noise_pct=0, \n",
    "            test_with_noise=True, \n",
    "            noiser=None, noise_args={}):\n",
    "    \n",
    "    use_noiser = False\n",
    "\n",
    "    if noiser is not None and train_noise_pct:\n",
    "        use_noiser = True\n",
    "        x_train_noise, y_train_noise = get_pct_data(x_train, y_train, train_noise_pct)\n",
    "        try_x_train = np.vstack((x_train, make_noise_set(x_train_noise, noiser, **noise_args)))\n",
    "        y_train = np.hstack((y_train, y_train_noise))                       \n",
    "    else:\n",
    "        try_x_train = x_train\n",
    "\n",
    "    if noiser is not None and test_with_noise:\n",
    "        use_noiser = True\n",
    "        try_x_test =  make_noise_set(x_test, noiser, **noise_args)\n",
    "        if x_test_adv is not None:\n",
    "            try_x_test_adv = make_noise_set(x_test_adv, noiser, **noise_args)\n",
    "        else:\n",
    "            try_x_test_adv = None\n",
    "    else:\n",
    "        try_x_test = x_test\n",
    "        try_x_test_adv = x_test_adv    \n",
    "\n",
    "    estimator.fit(try_x_train, y_train)\n",
    "    y_pred = estimator.predict(try_x_test)\n",
    "    test_score = accuracy_score(y_test, y_pred)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    if try_x_test_adv is not None:\n",
    "        y_pred_adv = estimator.predict(try_x_test_adv)\n",
    "        test_score_adv = accuracy_score(y_test, y_pred_adv)\n",
    "        confusion_mat_adv = confusion_matrix(y_test, y_pred_adv)\n",
    "    else:\n",
    "        test_score_adv = None\n",
    "        confusion_mat_adv = None\n",
    "        \n",
    "    return (\n",
    "        test_score, test_score_adv, \n",
    "        confusion_mat, confusion_mat_adv,\n",
    "        get_noiser_info(noiser if use_noiser else None, noise_args)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PR_SEQ = np.random.randint(0, 255, size=MNIST_SHAPE[0]*MNIST_SHAPE[1], dtype=np.uint8)\n",
    "\n",
    "def apply_pr(x):\n",
    "    return (((x*255).astype(np.uint8) ^ PR_SEQ).astype(np.float32) / 255).clip(0, 1)\n",
    "\n",
    "def map_pr(X):\n",
    "    return np.array([apply_pr(x) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def try_estimator(\n",
    "        x_train, y_train, x_test, y_test, x_test_adv,\n",
    "        estimator_class, hyperparams={},\n",
    "        noises=None, train_noise_pct=.1\n",
    "    ):\n",
    "    print(estimator_class.__name__)\n",
    "    results = []\n",
    "    for noiser, noise_args in noises if noises else [(None, None)]:\n",
    "        for train_with_noise, test_with_noise in itertools.product([0, 1], [False, True]): \n",
    "            if noiser is None and (train_with_noise or test_with_noise):\n",
    "                continue\n",
    "            if noiser is not None and not train_with_noise and not test_with_noise:\n",
    "                continue\n",
    "            start_time = time.time()\n",
    "            estimator = estimator_class(**hyperparams)\n",
    "            test_score, test_score_adv, confusion_mat, confusion_mat_adv, noiser_info = \\\n",
    "                try_one(estimator, \n",
    "                        x_train, y_train, \n",
    "                        x_test, y_test, x_test_adv,\n",
    "                        train_noise_pct=train_with_noise*train_noise_pct, \n",
    "                        test_with_noise=test_with_noise,\n",
    "                        noiser=noiser, noise_args=noise_args)\n",
    "            end_time = time.time()\n",
    "            estimator_info = estimator.__class__.__name__ # re.sub(r'[\\n\\s]+', ' ', repr(estimator)).strip()\n",
    "            result = {}\n",
    "            result['estimator'] = estimator_info\n",
    "            result['noise'] = noiser_info\n",
    "            result['train_noise_pct'] = train_with_noise*train_noise_pct\n",
    "            result['test_with_noise'] = test_with_noise \n",
    "            result['test_score'] = test_score\n",
    "            result['test_score_adv'] = test_score_adv\n",
    "            pprint.pprint(result)\n",
    "            result['confusion_mat'] = confusion_mat\n",
    "            result['confusion_mat_adv'] = confusion_mat_adv\n",
    "            results.append(result)\n",
    "            print(\"Completed in {:.06f} sec\".format(end_time - start_time))\n",
    "            print()\n",
    "            sys.stdout.flush()\n",
    "    return results, end_time\n",
    "\n",
    "def save_results(results, ts=None):\n",
    "    if not os.path.isdir(LOG_DIR):\n",
    "        os.makedirs(LOG_DIR)\n",
    "    pkl_file = time.strftime(\n",
    "        '{}/mnist_adv_test-%Y-%m-%d-%H-%M-%S-{}-{}.pkl'.format(\n",
    "            LOG_DIR, os.uname().nodename, os.getpid()\n",
    "        ),\n",
    "        time.localtime(ts)\n",
    "    )\n",
    "    with open(pkl_file, 'wb') as f :\n",
    "        pickle.Pickler(f).dump(results)\n",
    "    return pkl_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(argv=None):\n",
    "    from sklearn.neighbors import \\\n",
    "        KNeighborsClassifier\n",
    "\n",
    "    from sklearn.svm import \\\n",
    "        SVC\n",
    "\n",
    "    from sklearn.linear_model import \\\n",
    "        LogisticRegression\n",
    "\n",
    "    from mnist_keras_cnn import \\\n",
    "        MNIST_K_CNN\n",
    "\n",
    "    estimators = [\n",
    "        (\n",
    "            KNeighborsClassifier, \n",
    "            dict(\n",
    "                algorithm='kd_tree', leaf_size=30, metric='euclidean',\n",
    "                metric_params=None, n_jobs=8, n_neighbors=5, p=2,\n",
    "                weights='distance'\n",
    "            )\n",
    "        ),\n",
    "\n",
    "        (\n",
    "            SVC,\n",
    "            dict(\n",
    "                C=100.0, kernel='rbf',\n",
    "            )\n",
    "        ),\n",
    "\n",
    "        (\n",
    "            LogisticRegression,\n",
    "            dict(\n",
    "                C=1.27, class_weight='balanced', max_iter=1000,\n",
    "                multi_class='ovr', penalty='l1', solver='liblinear',\n",
    "            )\n",
    "        ),\n",
    "\n",
    "        (\n",
    "            MNIST_K_CNN,\n",
    "            dict(\n",
    "                epochs=5, verbose=1\n",
    "            )\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    noises = [\n",
    "        (None, None),\n",
    "\n",
    "        #(noise_utils.white_noise, dict(sigma=.01)),\n",
    "        #(noise_utils.white_noise, dict(sigma=.02)),\n",
    "        (noise_utils.white_noise, dict(sigma=.05)),\n",
    "        (noise_utils.white_noise, dict(sigma=.1)),\n",
    "        (noise_utils.white_noise, dict(sigma=.2)),\n",
    "        #(noise_utils.white_noise, dict(sigma=.5)),\n",
    "\n",
    "        (pil_utils.gaussian_blur_filter, dict(radius=2)),\n",
    "        #(pil_utils.gaussian_blur_filter, dict(radius=5)),\n",
    "\n",
    "        (pil_utils.smooth_filter, {}),\n",
    "        #(pil_utils.smooth_more_filter, {}),\n",
    "\n",
    "        #(pil_utils.rank_filter, {}),\n",
    "        #(pil_utils.median_filter, {}),\n",
    "        #(pil_utils.min_filter, {}),\n",
    "        (pil_utils.max_filter, {}),     \n",
    "\n",
    "        #(pil_utils.kernel_filter, dict(size=(3, 3), kernel=[.1, .2, .1, .2, .8, .2, .1, .2, .1])),\n",
    "    ]    \n",
    "    \n",
    "    parser = argparse.ArgumentParser(description='MNIST Adv Test.')\n",
    "    \n",
    "    parser.add_argument('-s', '--selector', type=int, default=0)\n",
    "    parser.add_argument('-p', '--use-p', type=float, default=0)\n",
    "    parser.add_argument('-n', '--train-noise-pct', type=float, default=0.1)\n",
    "    parser.add_argument('-a', '--train-adv-p', type=float, default=0)\n",
    "    parser.add_argument('-x', '--xor-pr', action='store_true', default=False)\n",
    "    parser.add_argument('data_file', default=DATA_FILE, nargs='?')\n",
    "    args = parser.parse_args(argv)\n",
    "    \n",
    "    estimator_class, hyperparams = estimators[args.selector]\n",
    "\n",
    "    x_train, y_train, x_test, y_test, x_test_adv = \\\n",
    "        load_data(\n",
    "            data_file=args.data_file,\n",
    "            use_p=args.use_p, \n",
    "            train_adv_p=args.train_adv_p\n",
    "        )    \n",
    "    \n",
    "    if args.xor_pr:\n",
    "        x_train = map_pr(x_train)\n",
    "        x_test = map_pr(x_test)\n",
    "        x_test_adv = map_pr(x_test_adv)\n",
    "    \n",
    "    results, end_time = try_estimator(\n",
    "        x_train, y_train, x_test, y_test, x_test_adv,\n",
    "        estimator_class, hyperparams=hyperparams,\n",
    "        noises=None if (args.xor_pr or args.train_adv_p) else noises,\n",
    "        train_noise_pct=args.train_noise_pct\n",
    "    )\n",
    "    \n",
    "    # Suplement the global flags:\n",
    "    for result in results:\n",
    "        result['xor_pr'] = args.xor_pr\n",
    "        result['train_adv_p'] = args.train_adv_p\n",
    "    \n",
    "    pkl_file = save_results(results, end_time)\n",
    "    print(\"Results saved to {}\".format(pkl_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main(['-s', '3', '-p', '.3', DATA_FILE] if plot_ok else None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
